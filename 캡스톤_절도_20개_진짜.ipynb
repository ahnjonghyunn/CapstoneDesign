{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahnjonghyunn/CapstoneDesign/blob/main/%EC%BA%A1%EC%8A%A4%ED%86%A4_%EC%A0%88%EB%8F%84_20%EA%B0%9C_%EC%A7%84%EC%A7%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPc8YDNHMA3t",
        "outputId": "2856b18c-7e69-4d3e-880e-584ae31ea998"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0Fwwe83qs61J",
        "outputId": "c70cc21b-a560-4810-d17c-3ab85829c935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.23-py3-none-any.whl (778 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.7/778.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.23\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (23.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (0.4.26+cuda12.cudnn89)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe) (1.25.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe) (4.8.0.76)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.7-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe) (1.11.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Installing collected packages: protobuf, sounddevice, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.3 sounddevice-0.4.7\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "!pip install mediapipe\n",
        "!pip install numpy pandas opencv-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK9DpfEp4wzt"
      },
      "source": [
        "# 이상행위 영상 분할\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vrluRw2FFKnj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def clip_videos(video_paths, abnormal_clip_dir, normal_clip_dir, abnormal_intervals_dict, clip_duration=10, fps=30):\n",
        "    if not os.path.exists(abnormal_clip_dir):\n",
        "        os.makedirs(abnormal_clip_dir)\n",
        "    if not os.path.exists(normal_clip_dir):\n",
        "        os.makedirs(normal_clip_dir)\n",
        "\n",
        "    for video_path in video_paths:\n",
        "        video = VideoFileClip(video_path)\n",
        "        total_duration = int(video.duration)\n",
        "        clip_count_abnormal = 0\n",
        "        clip_count_normal = 0\n",
        "\n",
        "        video_name = os.path.basename(video_path)\n",
        "        abnormal_intervals = abnormal_intervals_dict.get(video_path, [])\n",
        "\n",
        "        for start_time in range(0, total_duration, clip_duration):\n",
        "            end_time = min(start_time + clip_duration, total_duration)\n",
        "            clip = video.subclip(start_time, end_time)\n",
        "\n",
        "            is_abnormal = any(start_time <= t < end_time for t in abnormal_intervals)\n",
        "            if is_abnormal:\n",
        "                clip_path = os.path.join(abnormal_clip_dir, f'abnormal_clip_{video_name}_{clip_count_abnormal}.mp4')\n",
        "                clip_count_abnormal += 1\n",
        "            else:\n",
        "                clip_path = os.path.join(normal_clip_dir, f'normal_clip_{video_name}_{clip_count_normal}.mp4')\n",
        "                clip_count_normal += 1\n",
        "\n",
        "            clip.write_videofile(clip_path, codec=\"libx264\", fps=fps)\n",
        "\n",
        "video_paths = [\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도11.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도12.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도13.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도14.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도15.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도16.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도17.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도18.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도19.mp4',\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도20.mp4'\n",
        "]\n",
        "\n",
        "abnormal_clip_dir = '/content/drive/MyDrive/capstone_data/data/Training/clipped_videos/abnormal'\n",
        "normal_clip_dir = '/content/drive/MyDrive/capstone_data/data/Training/clipped_videos/normal'\n",
        "\n",
        "abnormal_intervals_dict = {\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도11.mp4': [10, 21, 43],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도12.mp4': [10, 21, 40],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도13.mp4': [10, 21, 41],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도14.mp4': [10, 39, 50],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도15.mp4': [10, 38, 49],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도16.mp4': [10, 39, 50],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도17.mp4': [10, 21, 43],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도18.mp4': [10, 22, 43],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도19.mp4': [10, 22, 40],\n",
        "    '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도20/절도20.mp4': [10, 38, 49]\n",
        "}\n",
        "\n",
        "clip_videos(video_paths, abnormal_clip_dir, normal_clip_dir, abnormal_intervals_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6pCeBLeMHaM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 비디오 클립 추출 사용 예제\n",
        "#video_paths = [\n",
        "   # '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도10/절도9.mp4',\n",
        "   # '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도10/절도10.mp4'\n",
        "#]\n",
        "#abnormal_clip_dir = '/content/drive/MyDrive/capstone_data/data/Training/clipped_videos_jong/abnormal'\n",
        "#normal_clip_dir = '/content/drive/MyDrive/capstone_data/data/Training/clipped_videos_jong/normal'\n",
        "#bnormal_intervals_dict = {\n",
        "  #  '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도10/절도9.mp4': [20, 31, 43],\n",
        "   # '/content/drive/MyDrive/capstone_data/data/Training/source_data/test_절도10/절도10.mp4': [10, 21, 41]\n",
        "#}\n",
        "\n",
        "#clip_videos(video_paths, abnormal_clip_dir, normal_clip_dir, abnormal_intervals_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-V4I_oGOGL0"
      },
      "source": [
        "#영상 확인 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pz5MLifIIRXb"
      },
      "outputs": [],
      "source": [
        "#from IPython.display import HTML\n",
        "#from base64 import b64encode\n",
        "\n",
        "#def display_videos(video_paths):\n",
        "#    video_tags = \"\"\n",
        "#    for video_path in video_paths:\n",
        "        # 비디오 파일을 base64로 인코딩\n",
        "#        video = open(video_path, \"rb\").read()\n",
        "#        video_encoded = b64encode(video).decode(\"ascii\")\n",
        "\n",
        "        # HTML로 비디오 재생 태그 추가\n",
        "#        video_tags += f\"\"\"\n",
        "#        <video width=\"640\" height=\"480\" controls>\n",
        "#            <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n",
        "#        </video>\n",
        "#        <br>\n",
        "#        \"\"\"\n",
        "\n",
        "#   return HTML(data=video_tags)\n",
        "\n",
        "# 사용 예시\n",
        "#video_paths = [\n",
        "#    \"/content/drive/MyDrive/capstone_data/data/Training/clipped_videos_jong/normal/normal_clip_절도9.mp4_0.mp4\", #\n",
        "#    \"/content/drive/MyDrive/capstone_data/data/Training/clipped_videos_jong/normal/normal_clip_절도9.mp4_1.mp4\", # 25\n",
        "#    \"/content/drive/MyDrive/capstone_data/data/Training/clipped_videos_jong/normal/normal_clip_절도9.mp4_2.mp4\",\n",
        "#    \"/content/drive/MyDrive/capstone_data/data/Training/clipped_videos_jong/abnormal/abnormal_clip_절도9.mp4_0.mp4\",#20\n",
        "#    \"/content/drive/MyDrive/capstone_data/data/Training/clipped_videos_jong/abnormal/abnormal_clip_절도9.mp4_0.mp4\",# 31\n",
        "#    \"/content/drive/MyDrive/capstone_data/data/Training/clipped_videos_jong/abnormal/abnormal_clip_절도9.mp4_0.mp4\",# 43\n",
        "#\n",
        "#]\n",
        "\n",
        "#display_videos(video_paths)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsnBrtOKOdy2"
      },
      "source": [
        "#비디오 파일에서 랜드마크 추출"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD-8heoqOXry",
        "outputId": "36d94299-1878-469e-ad81-8bac388a5e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6.23M/6.23M [00:00<00:00, 78.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# YOLOv8 모델 로드\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "# MediaPipe 초기화\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "def detect_people(image):\n",
        "    results = model(image)\n",
        "    persons = []\n",
        "    for det in results[0].boxes:\n",
        "        if det.cls == 0:  # 0은 COCO dataset에서 사람을 의미\n",
        "            persons.append(det.xyxy.cpu().numpy())\n",
        "    return persons\n",
        "\n",
        "def extract_landmarks(image, person_box):\n",
        "    x_min, y_min, x_max, y_max = map(int, person_box[0])\n",
        "    person_image = image[y_min:y_max, x_min:x_max]\n",
        "\n",
        "    with mp_pose.Pose(static_image_mode=True) as pose:\n",
        "        results = pose.process(cv2.cvtColor(person_image, cv2.COLOR_BGR2RGB))\n",
        "        if results.pose_landmarks:\n",
        "            landmarks = results.pose_landmarks.landmark\n",
        "            return [(lm.x, lm.y) for lm in landmarks]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "def process_clips(clip_dir, max_landmarks_per_clip=500):\n",
        "    clips = [os.path.join(clip_dir, clip) for clip in os.listdir(clip_dir) if clip.endswith('.mp4')]\n",
        "    all_landmarks = []\n",
        "\n",
        "    for clip_path in clips:\n",
        "        cap = cv2.VideoCapture(clip_path)\n",
        "        landmarks_count = 0\n",
        "        while cap.isOpened() and landmarks_count < max_landmarks_per_clip:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            people_boxes = detect_people(frame)\n",
        "            for box in people_boxes:\n",
        "                lm = extract_landmarks(frame, box)\n",
        "                if lm:\n",
        "                    all_landmarks.append(lm)\n",
        "                    landmarks_count += 1\n",
        "                    if landmarks_count >= max_landmarks_per_clip:\n",
        "                        break\n",
        "        cap.release()\n",
        "\n",
        "    return all_landmarks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amTDr-qnO1m1"
      },
      "source": [
        "#랜드마크 추출함수 실행"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bnw0lyIGO0h1",
        "outputId": "4357feef-2713-4bd9-8066-2205b5968fda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 2 persons, 1 donut, 498.7ms\n",
            "Speed: 25.3ms preprocess, 498.7ms inference, 3321.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "0: 384x640 2 bottles, 224.2ms\n",
            "Speed: 4.6ms preprocess, 224.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 232.2ms\n",
            "Speed: 4.3ms preprocess, 232.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 163.4ms\n",
            "Speed: 6.9ms preprocess, 163.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 159.9ms\n",
            "Speed: 4.2ms preprocess, 159.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 145.8ms\n",
            "Speed: 5.6ms preprocess, 145.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 161.5ms\n",
            "Speed: 4.6ms preprocess, 161.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 148.0ms\n",
            "Speed: 5.2ms preprocess, 148.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 145.2ms\n",
            "Speed: 4.1ms preprocess, 145.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 151.0ms\n",
            "Speed: 4.2ms preprocess, 151.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 142.5ms\n",
            "Speed: 8.8ms preprocess, 142.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 141.9ms\n",
            "Speed: 4.8ms preprocess, 141.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 151.1ms\n",
            "Speed: 5.8ms preprocess, 151.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 154.2ms\n",
            "Speed: 5.3ms preprocess, 154.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 141.9ms\n",
            "Speed: 4.4ms preprocess, 141.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 154.3ms\n",
            "Speed: 4.5ms preprocess, 154.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 147.9ms\n",
            "Speed: 4.5ms preprocess, 147.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 138.7ms\n",
            "Speed: 9.5ms preprocess, 138.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 143.8ms\n",
            "Speed: 4.1ms preprocess, 143.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 123.6ms\n",
            "Speed: 4.9ms preprocess, 123.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 126.1ms\n",
            "Speed: 4.7ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 131.5ms\n",
            "Speed: 3.8ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 126.7ms\n",
            "Speed: 3.8ms preprocess, 126.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 125.4ms\n",
            "Speed: 4.1ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 134.9ms\n",
            "Speed: 3.7ms preprocess, 134.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 163.2ms\n",
            "Speed: 6.8ms preprocess, 163.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 151.7ms\n",
            "Speed: 4.5ms preprocess, 151.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 135.8ms\n",
            "Speed: 4.7ms preprocess, 135.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 136.3ms\n",
            "Speed: 4.0ms preprocess, 136.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 146.0ms\n",
            "Speed: 4.5ms preprocess, 146.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 158.5ms\n",
            "Speed: 4.4ms preprocess, 158.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 146.2ms\n",
            "Speed: 4.5ms preprocess, 146.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 149.2ms\n",
            "Speed: 4.2ms preprocess, 149.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 144.3ms\n",
            "Speed: 4.5ms preprocess, 144.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 147.8ms\n",
            "Speed: 6.5ms preprocess, 147.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 144.0ms\n",
            "Speed: 4.8ms preprocess, 144.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 152.6ms\n",
            "Speed: 4.2ms preprocess, 152.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 134.7ms\n",
            "Speed: 4.8ms preprocess, 134.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 147.9ms\n",
            "Speed: 5.1ms preprocess, 147.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 143.0ms\n",
            "Speed: 4.1ms preprocess, 143.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 153.1ms\n",
            "Speed: 4.6ms preprocess, 153.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 145.2ms\n",
            "Speed: 4.3ms preprocess, 145.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 163.5ms\n",
            "Speed: 4.4ms preprocess, 163.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 156.5ms\n",
            "Speed: 5.2ms preprocess, 156.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 143.0ms\n",
            "Speed: 4.1ms preprocess, 143.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 142.5ms\n",
            "Speed: 4.7ms preprocess, 142.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 143.2ms\n",
            "Speed: 4.3ms preprocess, 143.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 141.9ms\n",
            "Speed: 5.0ms preprocess, 141.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 155.2ms\n",
            "Speed: 4.8ms preprocess, 155.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 158.9ms\n",
            "Speed: 5.7ms preprocess, 158.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 144.7ms\n",
            "Speed: 4.1ms preprocess, 144.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 169.2ms\n",
            "Speed: 4.2ms preprocess, 169.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 221.3ms\n",
            "Speed: 4.5ms preprocess, 221.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 226.0ms\n",
            "Speed: 4.1ms preprocess, 226.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 233.7ms\n",
            "Speed: 4.2ms preprocess, 233.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 219.8ms\n",
            "Speed: 4.1ms preprocess, 219.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 229.9ms\n",
            "Speed: 8.2ms preprocess, 229.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 210.6ms\n",
            "Speed: 4.3ms preprocess, 210.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 197.5ms\n",
            "Speed: 4.2ms preprocess, 197.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 198.2ms\n",
            "Speed: 3.6ms preprocess, 198.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 197.8ms\n",
            "Speed: 3.8ms preprocess, 197.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 209.5ms\n",
            "Speed: 3.7ms preprocess, 209.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 212.7ms\n",
            "Speed: 3.6ms preprocess, 212.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 213.9ms\n",
            "Speed: 3.4ms preprocess, 213.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 227.3ms\n",
            "Speed: 3.7ms preprocess, 227.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 128.0ms\n",
            "Speed: 6.7ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 125.2ms\n",
            "Speed: 3.7ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 147.8ms\n",
            "Speed: 4.8ms preprocess, 147.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 143.2ms\n",
            "Speed: 3.9ms preprocess, 143.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 137.9ms\n",
            "Speed: 4.3ms preprocess, 137.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 128.7ms\n",
            "Speed: 3.9ms preprocess, 128.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 128.2ms\n",
            "Speed: 4.3ms preprocess, 128.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 126.5ms\n",
            "Speed: 5.2ms preprocess, 126.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 129.5ms\n",
            "Speed: 4.6ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 146.1ms\n",
            "Speed: 3.7ms preprocess, 146.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 139.6ms\n",
            "Speed: 4.1ms preprocess, 139.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 140.0ms\n",
            "Speed: 4.4ms preprocess, 140.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 127.2ms\n",
            "Speed: 10.6ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 144.6ms\n",
            "Speed: 4.7ms preprocess, 144.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 135.0ms\n",
            "Speed: 4.7ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 127.6ms\n",
            "Speed: 4.3ms preprocess, 127.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 132.1ms\n",
            "Speed: 4.1ms preprocess, 132.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 134.4ms\n",
            "Speed: 4.4ms preprocess, 134.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 148.3ms\n",
            "Speed: 4.3ms preprocess, 148.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 142.9ms\n",
            "Speed: 5.3ms preprocess, 142.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 144.4ms\n",
            "Speed: 4.0ms preprocess, 144.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 200.5ms\n",
            "Speed: 3.8ms preprocess, 200.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 229.2ms\n",
            "Speed: 4.4ms preprocess, 229.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 216.5ms\n",
            "Speed: 4.9ms preprocess, 216.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 253.4ms\n",
            "Speed: 4.3ms preprocess, 253.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 236.2ms\n",
            "Speed: 8.4ms preprocess, 236.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 225.6ms\n",
            "Speed: 7.1ms preprocess, 225.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 225.0ms\n",
            "Speed: 4.6ms preprocess, 225.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 149.8ms\n",
            "Speed: 5.0ms preprocess, 149.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 136.8ms\n",
            "Speed: 4.7ms preprocess, 136.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 126.0ms\n",
            "Speed: 6.9ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 127.4ms\n",
            "Speed: 3.6ms preprocess, 127.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 130.8ms\n",
            "Speed: 3.8ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 129.4ms\n",
            "Speed: 3.9ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 127.5ms\n",
            "Speed: 5.2ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 133.5ms\n",
            "Speed: 4.2ms preprocess, 133.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 125.7ms\n",
            "Speed: 4.7ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 128.9ms\n",
            "Speed: 6.3ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 124.0ms\n",
            "Speed: 4.0ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 125.4ms\n",
            "Speed: 3.8ms preprocess, 125.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 127.6ms\n",
            "Speed: 4.0ms preprocess, 127.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 124.0ms\n",
            "Speed: 3.7ms preprocess, 124.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 127.1ms\n",
            "Speed: 3.6ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 140.5ms\n",
            "Speed: 6.1ms preprocess, 140.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 166.4ms\n",
            "Speed: 7.4ms preprocess, 166.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 143.4ms\n",
            "Speed: 6.7ms preprocess, 143.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 137.7ms\n",
            "Speed: 8.3ms preprocess, 137.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 139.8ms\n",
            "Speed: 4.1ms preprocess, 139.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 125.6ms\n",
            "Speed: 5.5ms preprocess, 125.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 135.9ms\n",
            "Speed: 3.7ms preprocess, 135.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 125.6ms\n",
            "Speed: 5.1ms preprocess, 125.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 135.1ms\n",
            "Speed: 4.9ms preprocess, 135.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 143.8ms\n",
            "Speed: 9.2ms preprocess, 143.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 136.2ms\n",
            "Speed: 4.2ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 199.4ms\n",
            "Speed: 4.2ms preprocess, 199.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 204.5ms\n",
            "Speed: 3.6ms preprocess, 204.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 201.7ms\n",
            "Speed: 4.3ms preprocess, 201.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 206.9ms\n",
            "Speed: 3.7ms preprocess, 206.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 239.1ms\n",
            "Speed: 9.8ms preprocess, 239.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 220.3ms\n",
            "Speed: 8.3ms preprocess, 220.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 328.4ms\n",
            "Speed: 7.3ms preprocess, 328.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 171.3ms\n",
            "Speed: 7.6ms preprocess, 171.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 137.2ms\n",
            "Speed: 4.1ms preprocess, 137.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 133.5ms\n",
            "Speed: 6.6ms preprocess, 133.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 152.3ms\n",
            "Speed: 4.0ms preprocess, 152.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 137.7ms\n",
            "Speed: 4.3ms preprocess, 137.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 140.4ms\n",
            "Speed: 4.2ms preprocess, 140.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 141.2ms\n",
            "Speed: 4.1ms preprocess, 141.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 123.5ms\n",
            "Speed: 4.6ms preprocess, 123.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 125.9ms\n",
            "Speed: 3.5ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 139.4ms\n",
            "Speed: 3.6ms preprocess, 139.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 141.0ms\n",
            "Speed: 4.3ms preprocess, 141.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 167.2ms\n",
            "Speed: 5.1ms preprocess, 167.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 136.5ms\n",
            "Speed: 4.2ms preprocess, 136.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 139.6ms\n",
            "Speed: 4.0ms preprocess, 139.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 133.1ms\n",
            "Speed: 7.9ms preprocess, 133.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 136.3ms\n",
            "Speed: 4.0ms preprocess, 136.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 147.8ms\n",
            "Speed: 4.2ms preprocess, 147.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 145.9ms\n",
            "Speed: 4.0ms preprocess, 145.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 138.0ms\n",
            "Speed: 4.8ms preprocess, 138.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 146.6ms\n",
            "Speed: 4.7ms preprocess, 146.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 126.7ms\n",
            "Speed: 4.6ms preprocess, 126.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 126.8ms\n",
            "Speed: 3.6ms preprocess, 126.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 130.1ms\n",
            "Speed: 4.4ms preprocess, 130.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 145.0ms\n",
            "Speed: 4.6ms preprocess, 145.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 167.4ms\n",
            "Speed: 5.1ms preprocess, 167.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 138.0ms\n",
            "Speed: 3.9ms preprocess, 138.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 222.7ms\n",
            "Speed: 10.2ms preprocess, 222.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 201.8ms\n",
            "Speed: 3.7ms preprocess, 201.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 216.4ms\n",
            "Speed: 4.8ms preprocess, 216.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 217.0ms\n",
            "Speed: 4.3ms preprocess, 217.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 244.4ms\n",
            "Speed: 4.1ms preprocess, 244.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 226.5ms\n",
            "Speed: 4.6ms preprocess, 226.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 221.5ms\n",
            "Speed: 6.2ms preprocess, 221.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 227.8ms\n",
            "Speed: 7.5ms preprocess, 227.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 154.0ms\n",
            "Speed: 4.0ms preprocess, 154.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 142.6ms\n",
            "Speed: 5.2ms preprocess, 142.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 151.2ms\n",
            "Speed: 5.0ms preprocess, 151.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 131.8ms\n",
            "Speed: 4.6ms preprocess, 131.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 134.9ms\n",
            "Speed: 7.6ms preprocess, 134.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 131.1ms\n",
            "Speed: 5.2ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 122.2ms\n",
            "Speed: 3.8ms preprocess, 122.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 153.2ms\n",
            "Speed: 5.5ms preprocess, 153.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 138.8ms\n",
            "Speed: 4.6ms preprocess, 138.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 140.2ms\n",
            "Speed: 5.1ms preprocess, 140.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 134.4ms\n",
            "Speed: 4.2ms preprocess, 134.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 133.7ms\n",
            "Speed: 5.5ms preprocess, 133.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 135.7ms\n",
            "Speed: 5.0ms preprocess, 135.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 140.9ms\n",
            "Speed: 4.0ms preprocess, 140.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 146.7ms\n",
            "Speed: 5.9ms preprocess, 146.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 138.3ms\n",
            "Speed: 4.7ms preprocess, 138.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 140.7ms\n",
            "Speed: 4.2ms preprocess, 140.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 131.1ms\n",
            "Speed: 4.3ms preprocess, 131.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 128.3ms\n",
            "Speed: 5.1ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 132.9ms\n",
            "Speed: 3.6ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 141.2ms\n",
            "Speed: 4.2ms preprocess, 141.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 122.8ms\n",
            "Speed: 4.9ms preprocess, 122.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 132.9ms\n",
            "Speed: 4.3ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 137.7ms\n",
            "Speed: 3.6ms preprocess, 137.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 126.2ms\n",
            "Speed: 3.7ms preprocess, 126.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 132.2ms\n",
            "Speed: 3.7ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 227.6ms\n",
            "Speed: 4.4ms preprocess, 227.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 235.6ms\n",
            "Speed: 4.2ms preprocess, 235.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 227.6ms\n",
            "Speed: 4.7ms preprocess, 227.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 214.7ms\n",
            "Speed: 7.2ms preprocess, 214.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 202.6ms\n",
            "Speed: 3.7ms preprocess, 202.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 213.3ms\n",
            "Speed: 6.4ms preprocess, 213.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 217.9ms\n",
            "Speed: 3.7ms preprocess, 217.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 231.1ms\n",
            "Speed: 3.8ms preprocess, 231.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 140.8ms\n",
            "Speed: 4.7ms preprocess, 140.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 143.2ms\n",
            "Speed: 4.6ms preprocess, 143.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 140.0ms\n",
            "Speed: 5.3ms preprocess, 140.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 141.2ms\n",
            "Speed: 4.2ms preprocess, 141.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 146.5ms\n",
            "Speed: 7.4ms preprocess, 146.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 142.6ms\n",
            "Speed: 5.0ms preprocess, 142.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 138.6ms\n",
            "Speed: 4.2ms preprocess, 138.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 138.4ms\n",
            "Speed: 4.8ms preprocess, 138.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 135.8ms\n",
            "Speed: 4.6ms preprocess, 135.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 130.7ms\n",
            "Speed: 3.8ms preprocess, 130.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 127.2ms\n",
            "Speed: 5.2ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 125.2ms\n",
            "Speed: 5.5ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 129.4ms\n",
            "Speed: 4.4ms preprocess, 129.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 133.8ms\n",
            "Speed: 5.3ms preprocess, 133.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 125.8ms\n",
            "Speed: 3.8ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 128.5ms\n",
            "Speed: 9.9ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 143.1ms\n",
            "Speed: 3.6ms preprocess, 143.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 123.7ms\n",
            "Speed: 3.6ms preprocess, 123.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 146.1ms\n",
            "Speed: 6.7ms preprocess, 146.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 153.1ms\n",
            "Speed: 4.1ms preprocess, 153.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 141.5ms\n",
            "Speed: 7.6ms preprocess, 141.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 128.0ms\n",
            "Speed: 3.8ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 128.0ms\n",
            "Speed: 3.8ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 129.1ms\n",
            "Speed: 3.7ms preprocess, 129.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 139.5ms\n",
            "Speed: 3.6ms preprocess, 139.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 199.5ms\n",
            "Speed: 3.6ms preprocess, 199.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 216.2ms\n",
            "Speed: 7.1ms preprocess, 216.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 211.0ms\n",
            "Speed: 12.8ms preprocess, 211.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 book, 259.9ms\n",
            "Speed: 4.3ms preprocess, 259.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 199.7ms\n",
            "Speed: 3.8ms preprocess, 199.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 210.8ms\n",
            "Speed: 3.6ms preprocess, 210.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 228.7ms\n",
            "Speed: 4.9ms preprocess, 228.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 227.2ms\n",
            "Speed: 4.5ms preprocess, 227.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 167.6ms\n",
            "Speed: 4.2ms preprocess, 167.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 145.9ms\n",
            "Speed: 4.5ms preprocess, 145.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 137.4ms\n",
            "Speed: 11.3ms preprocess, 137.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 1 bottle, 1 book, 158.8ms\n",
            "Speed: 4.1ms preprocess, 158.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 1 bottle, 1 book, 129.8ms\n",
            "Speed: 5.9ms preprocess, 129.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 1 bottle, 1 book, 131.7ms\n",
            "Speed: 3.7ms preprocess, 131.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 1 book, 126.6ms\n",
            "Speed: 3.7ms preprocess, 126.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 1 book, 140.9ms\n",
            "Speed: 5.7ms preprocess, 140.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 1 book, 138.8ms\n",
            "Speed: 4.0ms preprocess, 138.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skis, 3 bottles, 1 book, 135.5ms\n",
            "Speed: 4.3ms preprocess, 135.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 1 book, 129.0ms\n",
            "Speed: 10.4ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 137.4ms\n",
            "Speed: 7.3ms preprocess, 137.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 124.1ms\n",
            "Speed: 3.8ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 1 book, 124.4ms\n",
            "Speed: 3.5ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 122.1ms\n",
            "Speed: 5.9ms preprocess, 122.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 141.8ms\n",
            "Speed: 8.6ms preprocess, 141.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 152.4ms\n",
            "Speed: 4.6ms preprocess, 152.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 136.9ms\n",
            "Speed: 6.6ms preprocess, 136.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 136.3ms\n",
            "Speed: 5.1ms preprocess, 136.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 142.1ms\n",
            "Speed: 4.8ms preprocess, 142.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 127.9ms\n",
            "Speed: 6.0ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 127.1ms\n",
            "Speed: 6.5ms preprocess, 127.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 128.8ms\n",
            "Speed: 5.0ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 203.9ms\n",
            "Speed: 4.3ms preprocess, 203.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 190.7ms\n",
            "Speed: 4.9ms preprocess, 190.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 231.4ms\n",
            "Speed: 6.4ms preprocess, 231.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 228.2ms\n",
            "Speed: 8.0ms preprocess, 228.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 213.7ms\n",
            "Speed: 8.3ms preprocess, 213.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 233.2ms\n",
            "Speed: 7.5ms preprocess, 233.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 248.8ms\n",
            "Speed: 8.6ms preprocess, 248.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 228.1ms\n",
            "Speed: 9.4ms preprocess, 228.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 225.4ms\n",
            "Speed: 6.9ms preprocess, 225.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 134.1ms\n",
            "Speed: 4.3ms preprocess, 134.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 150.7ms\n",
            "Speed: 14.8ms preprocess, 150.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 125.3ms\n",
            "Speed: 3.6ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 122.6ms\n",
            "Speed: 4.3ms preprocess, 122.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 146.2ms\n",
            "Speed: 3.8ms preprocess, 146.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 148.5ms\n",
            "Speed: 4.5ms preprocess, 148.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 136.2ms\n",
            "Speed: 4.6ms preprocess, 136.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 129.5ms\n",
            "Speed: 4.4ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 125.2ms\n",
            "Speed: 3.8ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 137.0ms\n",
            "Speed: 4.5ms preprocess, 137.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 148.2ms\n",
            "Speed: 4.4ms preprocess, 148.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 136.9ms\n",
            "Speed: 4.9ms preprocess, 136.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 131.3ms\n",
            "Speed: 3.8ms preprocess, 131.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 125.7ms\n",
            "Speed: 3.6ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 125.0ms\n",
            "Speed: 3.7ms preprocess, 125.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 130.7ms\n",
            "Speed: 3.7ms preprocess, 130.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 129.0ms\n",
            "Speed: 3.7ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 123.5ms\n",
            "Speed: 4.6ms preprocess, 123.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 156.0ms\n",
            "Speed: 4.5ms preprocess, 156.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 148.6ms\n",
            "Speed: 4.3ms preprocess, 148.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 160.9ms\n",
            "Speed: 4.4ms preprocess, 160.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 3 bottles, 1 book, 131.6ms\n",
            "Speed: 3.5ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 129.5ms\n",
            "Speed: 3.5ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 136.4ms\n",
            "Speed: 5.0ms preprocess, 136.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 138.7ms\n",
            "Speed: 6.1ms preprocess, 138.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 refrigerator, 1 book, 218.8ms\n",
            "Speed: 6.4ms preprocess, 218.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 refrigerator, 1 book, 192.3ms\n",
            "Speed: 3.8ms preprocess, 192.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 refrigerator, 1 book, 235.7ms\n",
            "Speed: 7.9ms preprocess, 235.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 refrigerator, 1 book, 236.8ms\n",
            "Speed: 4.4ms preprocess, 236.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 refrigerator, 1 book, 209.9ms\n",
            "Speed: 3.9ms preprocess, 209.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 refrigerator, 1 book, 213.0ms\n",
            "Speed: 7.8ms preprocess, 213.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 238.6ms\n",
            "Speed: 4.4ms preprocess, 238.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 refrigerator, 1 book, 255.2ms\n",
            "Speed: 4.3ms preprocess, 255.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 151.6ms\n",
            "Speed: 4.5ms preprocess, 151.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 146.4ms\n",
            "Speed: 5.3ms preprocess, 146.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 148.5ms\n",
            "Speed: 4.2ms preprocess, 148.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 143.7ms\n",
            "Speed: 4.6ms preprocess, 143.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 141.4ms\n",
            "Speed: 4.5ms preprocess, 141.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 138.2ms\n",
            "Speed: 4.3ms preprocess, 138.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 129.0ms\n",
            "Speed: 3.7ms preprocess, 129.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 126.0ms\n",
            "Speed: 3.5ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 128.3ms\n",
            "Speed: 4.5ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 127.9ms\n",
            "Speed: 3.7ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skateboard, 2 bottles, 1 book, 125.4ms\n",
            "Speed: 7.2ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 128.5ms\n",
            "Speed: 4.0ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 137.9ms\n",
            "Speed: 6.7ms preprocess, 137.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 125.4ms\n",
            "Speed: 5.0ms preprocess, 125.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 123.9ms\n",
            "Speed: 4.5ms preprocess, 123.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 148.0ms\n",
            "Speed: 4.9ms preprocess, 148.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 141.0ms\n",
            "Speed: 4.7ms preprocess, 141.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 144.7ms\n",
            "Speed: 4.2ms preprocess, 144.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 139.7ms\n",
            "Speed: 5.2ms preprocess, 139.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 138.1ms\n",
            "Speed: 5.2ms preprocess, 138.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 139.8ms\n",
            "Speed: 4.6ms preprocess, 139.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 131.6ms\n",
            "Speed: 6.2ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 137.1ms\n",
            "Speed: 7.1ms preprocess, 137.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 143.4ms\n",
            "Speed: 5.4ms preprocess, 143.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 155.0ms\n",
            "Speed: 4.9ms preprocess, 155.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 183.4ms\n",
            "Speed: 7.1ms preprocess, 183.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 227.6ms\n",
            "Speed: 4.1ms preprocess, 227.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 228.1ms\n",
            "Speed: 3.7ms preprocess, 228.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 200.4ms\n",
            "Speed: 3.8ms preprocess, 200.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 207.5ms\n",
            "Speed: 3.5ms preprocess, 207.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 skis, 2 bottles, 1 book, 196.8ms\n",
            "Speed: 4.1ms preprocess, 196.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 207.0ms\n",
            "Speed: 5.5ms preprocess, 207.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 203.6ms\n",
            "Speed: 3.8ms preprocess, 203.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 127.3ms\n",
            "Speed: 4.8ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 131.3ms\n",
            "Speed: 3.9ms preprocess, 131.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 131.3ms\n",
            "Speed: 4.1ms preprocess, 131.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 137.1ms\n",
            "Speed: 3.6ms preprocess, 137.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 128.1ms\n",
            "Speed: 9.2ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 140.1ms\n",
            "Speed: 4.3ms preprocess, 140.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 refrigerator, 127.5ms\n",
            "Speed: 4.4ms preprocess, 127.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 refrigerator, 129.3ms\n",
            "Speed: 3.5ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 140.6ms\n",
            "Speed: 4.0ms preprocess, 140.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 128.3ms\n",
            "Speed: 3.4ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 138.1ms\n",
            "Speed: 4.8ms preprocess, 138.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 142.4ms\n",
            "Speed: 5.1ms preprocess, 142.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 145.2ms\n",
            "Speed: 7.9ms preprocess, 145.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 124.3ms\n",
            "Speed: 4.6ms preprocess, 124.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 125.8ms\n",
            "Speed: 4.2ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 126.1ms\n",
            "Speed: 3.8ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 138.8ms\n",
            "Speed: 4.2ms preprocess, 138.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 125.8ms\n",
            "Speed: 3.7ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 136.2ms\n",
            "Speed: 4.4ms preprocess, 136.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 155.8ms\n",
            "Speed: 5.4ms preprocess, 155.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 153.3ms\n",
            "Speed: 5.5ms preprocess, 153.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 146.5ms\n",
            "Speed: 4.1ms preprocess, 146.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 136.7ms\n",
            "Speed: 5.2ms preprocess, 136.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 143.9ms\n",
            "Speed: 4.3ms preprocess, 143.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 172.3ms\n",
            "Speed: 4.1ms preprocess, 172.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 138.5ms\n",
            "Speed: 4.5ms preprocess, 138.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 234.3ms\n",
            "Speed: 4.5ms preprocess, 234.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 3 bottles, 1 book, 219.4ms\n",
            "Speed: 10.4ms preprocess, 219.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 231.7ms\n",
            "Speed: 7.6ms preprocess, 231.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 223.3ms\n",
            "Speed: 4.3ms preprocess, 223.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 221.6ms\n",
            "Speed: 19.5ms preprocess, 221.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 201.2ms\n",
            "Speed: 5.9ms preprocess, 201.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 230.9ms\n",
            "Speed: 8.0ms preprocess, 230.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 244.4ms\n",
            "Speed: 4.2ms preprocess, 244.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 142.8ms\n",
            "Speed: 4.0ms preprocess, 142.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 130.3ms\n",
            "Speed: 3.5ms preprocess, 130.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 128.3ms\n",
            "Speed: 3.5ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 125.6ms\n",
            "Speed: 4.7ms preprocess, 125.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 125.2ms\n",
            "Speed: 7.4ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 125.7ms\n",
            "Speed: 3.8ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 128.5ms\n",
            "Speed: 4.5ms preprocess, 128.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 126.0ms\n",
            "Speed: 4.4ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 129.8ms\n",
            "Speed: 3.5ms preprocess, 129.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 146.1ms\n",
            "Speed: 4.2ms preprocess, 146.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 161.0ms\n",
            "Speed: 4.1ms preprocess, 161.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 129.6ms\n",
            "Speed: 3.8ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 123.6ms\n",
            "Speed: 5.0ms preprocess, 123.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 123.4ms\n",
            "Speed: 4.3ms preprocess, 123.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 132.2ms\n",
            "Speed: 3.6ms preprocess, 132.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 124.2ms\n",
            "Speed: 3.8ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 125.8ms\n",
            "Speed: 3.9ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 145.1ms\n",
            "Speed: 4.1ms preprocess, 145.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 151.5ms\n",
            "Speed: 6.0ms preprocess, 151.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 141.5ms\n",
            "Speed: 5.6ms preprocess, 141.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 165.3ms\n",
            "Speed: 4.6ms preprocess, 165.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 142.6ms\n",
            "Speed: 5.0ms preprocess, 142.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 137.8ms\n",
            "Speed: 5.3ms preprocess, 137.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 135.7ms\n",
            "Speed: 4.4ms preprocess, 135.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 133.9ms\n",
            "Speed: 4.3ms preprocess, 133.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 128.1ms\n",
            "Speed: 3.8ms preprocess, 128.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 128.5ms\n",
            "Speed: 4.2ms preprocess, 128.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 212.6ms\n",
            "Speed: 4.2ms preprocess, 212.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 224.8ms\n",
            "Speed: 4.1ms preprocess, 224.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 211.8ms\n",
            "Speed: 4.2ms preprocess, 211.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 230.6ms\n",
            "Speed: 13.1ms preprocess, 230.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 238.4ms\n",
            "Speed: 8.7ms preprocess, 238.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 214.9ms\n",
            "Speed: 4.0ms preprocess, 214.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 236.5ms\n",
            "Speed: 3.7ms preprocess, 236.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 139.3ms\n",
            "Speed: 5.3ms preprocess, 139.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 146.9ms\n",
            "Speed: 5.6ms preprocess, 146.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 143.0ms\n",
            "Speed: 4.1ms preprocess, 143.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 137.5ms\n",
            "Speed: 4.3ms preprocess, 137.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 213.6ms\n",
            "Speed: 5.0ms preprocess, 213.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 132.8ms\n",
            "Speed: 4.4ms preprocess, 132.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 140.3ms\n",
            "Speed: 4.4ms preprocess, 140.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 140.0ms\n",
            "Speed: 4.2ms preprocess, 140.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 142.6ms\n",
            "Speed: 4.7ms preprocess, 142.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 2 bottles, 149.6ms\n",
            "Speed: 5.1ms preprocess, 149.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 138.7ms\n",
            "Speed: 4.3ms preprocess, 138.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 142.9ms\n",
            "Speed: 4.5ms preprocess, 142.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 144.4ms\n",
            "Speed: 4.5ms preprocess, 144.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 144.3ms\n",
            "Speed: 4.2ms preprocess, 144.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 154.7ms\n",
            "Speed: 4.1ms preprocess, 154.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 139.3ms\n",
            "Speed: 4.1ms preprocess, 139.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 146.0ms\n",
            "Speed: 3.9ms preprocess, 146.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 129.9ms\n",
            "Speed: 4.8ms preprocess, 129.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 127.2ms\n",
            "Speed: 5.6ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 127.4ms\n",
            "Speed: 4.2ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 127.4ms\n",
            "Speed: 3.6ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 130.9ms\n",
            "Speed: 4.6ms preprocess, 130.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 127.8ms\n",
            "Speed: 3.8ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 122.9ms\n",
            "Speed: 4.4ms preprocess, 122.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 126.0ms\n",
            "Speed: 9.9ms preprocess, 126.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 166.3ms\n",
            "Speed: 4.7ms preprocess, 166.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 205.2ms\n",
            "Speed: 10.0ms preprocess, 205.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 246.8ms\n",
            "Speed: 7.3ms preprocess, 246.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 217.4ms\n",
            "Speed: 6.7ms preprocess, 217.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 218.7ms\n",
            "Speed: 4.2ms preprocess, 218.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 228.4ms\n",
            "Speed: 4.8ms preprocess, 228.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 228.7ms\n",
            "Speed: 4.3ms preprocess, 228.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 221.2ms\n",
            "Speed: 4.4ms preprocess, 221.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 138.8ms\n",
            "Speed: 5.2ms preprocess, 138.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 138.9ms\n",
            "Speed: 4.1ms preprocess, 138.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 143.2ms\n",
            "Speed: 4.5ms preprocess, 143.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 147.6ms\n",
            "Speed: 4.1ms preprocess, 147.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 155.0ms\n",
            "Speed: 5.2ms preprocess, 155.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 144.5ms\n",
            "Speed: 5.4ms preprocess, 144.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 148.1ms\n",
            "Speed: 5.2ms preprocess, 148.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 144.9ms\n",
            "Speed: 4.4ms preprocess, 144.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 144.6ms\n",
            "Speed: 4.1ms preprocess, 144.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 169.8ms\n",
            "Speed: 4.5ms preprocess, 169.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 135.6ms\n",
            "Speed: 4.4ms preprocess, 135.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 151.9ms\n",
            "Speed: 4.2ms preprocess, 151.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 143.3ms\n",
            "Speed: 4.4ms preprocess, 143.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 145.9ms\n",
            "Speed: 4.3ms preprocess, 145.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 144.9ms\n",
            "Speed: 5.2ms preprocess, 144.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 143.1ms\n",
            "Speed: 3.9ms preprocess, 143.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 5 bottles, 133.8ms\n",
            "Speed: 5.9ms preprocess, 133.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 138.4ms\n",
            "Speed: 4.0ms preprocess, 138.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 145.5ms\n",
            "Speed: 3.9ms preprocess, 145.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 145.0ms\n",
            "Speed: 4.6ms preprocess, 145.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 150.7ms\n",
            "Speed: 4.5ms preprocess, 150.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 145.0ms\n",
            "Speed: 4.3ms preprocess, 145.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 147.1ms\n",
            "Speed: 4.8ms preprocess, 147.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 142.5ms\n",
            "Speed: 4.2ms preprocess, 142.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 234.7ms\n",
            "Speed: 7.6ms preprocess, 234.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 198.9ms\n",
            "Speed: 3.9ms preprocess, 198.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 202.3ms\n",
            "Speed: 3.9ms preprocess, 202.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 220.6ms\n",
            "Speed: 4.3ms preprocess, 220.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 224.0ms\n",
            "Speed: 7.7ms preprocess, 224.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 224.4ms\n",
            "Speed: 7.3ms preprocess, 224.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 243.3ms\n",
            "Speed: 7.8ms preprocess, 243.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 229.5ms\n",
            "Speed: 5.6ms preprocess, 229.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 140.3ms\n",
            "Speed: 8.8ms preprocess, 140.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 153.9ms\n",
            "Speed: 4.4ms preprocess, 153.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 146.5ms\n",
            "Speed: 4.8ms preprocess, 146.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 146.8ms\n",
            "Speed: 4.4ms preprocess, 146.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 150.1ms\n",
            "Speed: 4.6ms preprocess, 150.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 150.8ms\n",
            "Speed: 5.6ms preprocess, 150.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 141.2ms\n",
            "Speed: 4.3ms preprocess, 141.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 144.2ms\n",
            "Speed: 6.0ms preprocess, 144.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 126.4ms\n",
            "Speed: 3.7ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 144.4ms\n",
            "Speed: 3.4ms preprocess, 144.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 146.6ms\n",
            "Speed: 4.5ms preprocess, 146.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 138.6ms\n",
            "Speed: 4.0ms preprocess, 138.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 139.3ms\n",
            "Speed: 12.4ms preprocess, 139.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 151.5ms\n",
            "Speed: 4.1ms preprocess, 151.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 155.1ms\n",
            "Speed: 6.5ms preprocess, 155.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 128.9ms\n",
            "Speed: 4.1ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 124.9ms\n",
            "Speed: 8.0ms preprocess, 124.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 127.8ms\n",
            "Speed: 3.8ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 138.1ms\n",
            "Speed: 5.2ms preprocess, 138.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 138.0ms\n",
            "Speed: 4.4ms preprocess, 138.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 139.2ms\n",
            "Speed: 5.9ms preprocess, 139.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 130.4ms\n",
            "Speed: 3.7ms preprocess, 130.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 139.1ms\n",
            "Speed: 3.4ms preprocess, 139.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 133.2ms\n",
            "Speed: 4.0ms preprocess, 133.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 bottles, 1 book, 147.3ms\n",
            "Speed: 4.0ms preprocess, 147.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 222.4ms\n",
            "Speed: 8.1ms preprocess, 222.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 230.7ms\n",
            "Speed: 8.3ms preprocess, 230.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 232.7ms\n",
            "Speed: 4.4ms preprocess, 232.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 230.0ms\n",
            "Speed: 4.3ms preprocess, 230.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 223.9ms\n",
            "Speed: 4.0ms preprocess, 223.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 221.9ms\n",
            "Speed: 4.3ms preprocess, 221.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 228.5ms\n",
            "Speed: 4.3ms preprocess, 228.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 140.6ms\n",
            "Speed: 4.4ms preprocess, 140.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 144.4ms\n",
            "Speed: 4.6ms preprocess, 144.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 1 book, 137.5ms\n",
            "Speed: 5.7ms preprocess, 137.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 136.6ms\n",
            "Speed: 7.1ms preprocess, 136.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 133.0ms\n",
            "Speed: 4.5ms preprocess, 133.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 143.1ms\n",
            "Speed: 5.0ms preprocess, 143.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 144.2ms\n",
            "Speed: 4.1ms preprocess, 144.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 151.0ms\n",
            "Speed: 4.1ms preprocess, 151.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 126.3ms\n",
            "Speed: 3.7ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 123.3ms\n",
            "Speed: 4.6ms preprocess, 123.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 129.1ms\n",
            "Speed: 4.9ms preprocess, 129.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 125.5ms\n",
            "Speed: 4.5ms preprocess, 125.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 125.8ms\n",
            "Speed: 3.9ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 140.8ms\n",
            "Speed: 6.2ms preprocess, 140.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 148.0ms\n",
            "Speed: 8.1ms preprocess, 148.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 144.5ms\n",
            "Speed: 4.7ms preprocess, 144.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 141.1ms\n",
            "Speed: 4.8ms preprocess, 141.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 124.4ms\n",
            "Speed: 6.6ms preprocess, 124.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 125.3ms\n",
            "Speed: 4.4ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 125.9ms\n",
            "Speed: 10.2ms preprocess, 125.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 125.8ms\n",
            "Speed: 3.6ms preprocess, 125.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 131.8ms\n",
            "Speed: 4.0ms preprocess, 131.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 127.2ms\n",
            "Speed: 4.0ms preprocess, 127.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 148.3ms\n",
            "Speed: 4.4ms preprocess, 148.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 122.4ms\n",
            "Speed: 3.8ms preprocess, 122.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 219.4ms\n",
            "Speed: 3.8ms preprocess, 219.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 228.7ms\n",
            "Speed: 4.5ms preprocess, 228.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 226.9ms\n",
            "Speed: 10.3ms preprocess, 226.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 230.3ms\n",
            "Speed: 4.4ms preprocess, 230.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 226.8ms\n",
            "Speed: 4.3ms preprocess, 226.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 233.2ms\n",
            "Speed: 4.1ms preprocess, 233.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 254.7ms\n",
            "Speed: 4.4ms preprocess, 254.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 147.3ms\n",
            "Speed: 4.9ms preprocess, 147.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 140.6ms\n",
            "Speed: 4.5ms preprocess, 140.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 148.9ms\n",
            "Speed: 4.9ms preprocess, 148.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 143.1ms\n",
            "Speed: 4.8ms preprocess, 143.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 143.9ms\n",
            "Speed: 4.5ms preprocess, 143.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 133.9ms\n",
            "Speed: 8.1ms preprocess, 133.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 124.1ms\n",
            "Speed: 3.9ms preprocess, 124.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 135.8ms\n",
            "Speed: 3.6ms preprocess, 135.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 144.8ms\n",
            "Speed: 5.1ms preprocess, 144.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 190.5ms\n",
            "Speed: 4.2ms preprocess, 190.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 bottles, 1 book, 139.8ms\n",
            "Speed: 3.6ms preprocess, 139.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 125.3ms\n",
            "Speed: 3.7ms preprocess, 125.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 122.9ms\n",
            "Speed: 3.6ms preprocess, 122.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 146.6ms\n",
            "Speed: 8.1ms preprocess, 146.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 154.9ms\n",
            "Speed: 5.0ms preprocess, 154.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 153.0ms\n",
            "Speed: 7.5ms preprocess, 153.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 145.1ms\n",
            "Speed: 4.5ms preprocess, 145.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 141.4ms\n",
            "Speed: 5.8ms preprocess, 141.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 180.7ms\n",
            "Speed: 3.5ms preprocess, 180.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 129.2ms\n",
            "Speed: 9.2ms preprocess, 129.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 134.0ms\n",
            "Speed: 3.5ms preprocess, 134.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 127.1ms\n",
            "Speed: 3.9ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 125.4ms\n",
            "Speed: 4.3ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 160.2ms\n",
            "Speed: 4.0ms preprocess, 160.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 150.0ms\n",
            "Speed: 4.0ms preprocess, 150.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 207.6ms\n",
            "Speed: 7.6ms preprocess, 207.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 200.0ms\n",
            "Speed: 4.0ms preprocess, 200.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 251.9ms\n",
            "Speed: 15.4ms preprocess, 251.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 234.1ms\n",
            "Speed: 4.9ms preprocess, 234.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 235.3ms\n",
            "Speed: 4.5ms preprocess, 235.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 264.9ms\n",
            "Speed: 8.4ms preprocess, 264.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 194.1ms\n",
            "Speed: 6.2ms preprocess, 194.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 159.1ms\n",
            "Speed: 7.0ms preprocess, 159.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 149.1ms\n",
            "Speed: 7.8ms preprocess, 149.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 138.9ms\n",
            "Speed: 5.4ms preprocess, 138.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 144.3ms\n",
            "Speed: 9.3ms preprocess, 144.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 130.1ms\n",
            "Speed: 5.0ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 143.6ms\n",
            "Speed: 3.7ms preprocess, 143.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 130.4ms\n",
            "Speed: 4.4ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 146.1ms\n",
            "Speed: 8.1ms preprocess, 146.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 141.2ms\n",
            "Speed: 5.8ms preprocess, 141.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 139.2ms\n",
            "Speed: 4.9ms preprocess, 139.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 153.8ms\n",
            "Speed: 4.1ms preprocess, 153.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 139.0ms\n",
            "Speed: 4.5ms preprocess, 139.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 139.9ms\n",
            "Speed: 5.3ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 137.8ms\n",
            "Speed: 4.4ms preprocess, 137.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 144.1ms\n",
            "Speed: 4.4ms preprocess, 144.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 161.7ms\n",
            "Speed: 7.6ms preprocess, 161.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 142.2ms\n",
            "Speed: 4.5ms preprocess, 142.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 126.8ms\n",
            "Speed: 6.3ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 book, 136.5ms\n",
            "Speed: 3.7ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 128.9ms\n",
            "Speed: 5.3ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 146.0ms\n",
            "Speed: 4.3ms preprocess, 146.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 135.7ms\n",
            "Speed: 4.4ms preprocess, 135.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 141.8ms\n",
            "Speed: 4.7ms preprocess, 141.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 144.3ms\n",
            "Speed: 7.8ms preprocess, 144.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 179.0ms\n",
            "Speed: 6.7ms preprocess, 179.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 229.4ms\n",
            "Speed: 4.2ms preprocess, 229.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 228.3ms\n",
            "Speed: 4.2ms preprocess, 228.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 245.3ms\n",
            "Speed: 4.8ms preprocess, 245.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 212.7ms\n",
            "Speed: 4.2ms preprocess, 212.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 220.6ms\n",
            "Speed: 4.2ms preprocess, 220.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 232.3ms\n",
            "Speed: 4.5ms preprocess, 232.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 232.5ms\n",
            "Speed: 4.1ms preprocess, 232.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 138.3ms\n",
            "Speed: 4.0ms preprocess, 138.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 138.3ms\n",
            "Speed: 5.0ms preprocess, 138.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 133.9ms\n",
            "Speed: 5.0ms preprocess, 133.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 152.3ms\n",
            "Speed: 9.7ms preprocess, 152.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 134.1ms\n",
            "Speed: 5.5ms preprocess, 134.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 139.2ms\n",
            "Speed: 4.6ms preprocess, 139.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 144.9ms\n",
            "Speed: 5.3ms preprocess, 144.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 139.2ms\n",
            "Speed: 4.2ms preprocess, 139.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 139.3ms\n",
            "Speed: 4.7ms preprocess, 139.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 144.1ms\n",
            "Speed: 4.4ms preprocess, 144.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 144.6ms\n",
            "Speed: 5.2ms preprocess, 144.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 157.8ms\n",
            "Speed: 8.0ms preprocess, 157.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 136.9ms\n",
            "Speed: 5.6ms preprocess, 136.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 143.0ms\n",
            "Speed: 4.3ms preprocess, 143.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 135.9ms\n",
            "Speed: 5.1ms preprocess, 135.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 133.6ms\n",
            "Speed: 4.8ms preprocess, 133.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 1 book, 146.7ms\n",
            "Speed: 5.2ms preprocess, 146.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 122.5ms\n",
            "Speed: 7.5ms preprocess, 122.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 127.9ms\n",
            "Speed: 3.6ms preprocess, 127.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 129.5ms\n",
            "Speed: 3.5ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 147.2ms\n",
            "Speed: 5.7ms preprocess, 147.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 159.7ms\n",
            "Speed: 4.4ms preprocess, 159.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 141.2ms\n",
            "Speed: 4.3ms preprocess, 141.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 139.4ms\n",
            "Speed: 7.7ms preprocess, 139.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 136.0ms\n",
            "Speed: 4.8ms preprocess, 136.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 215.9ms\n",
            "Speed: 5.4ms preprocess, 215.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 219.5ms\n",
            "Speed: 8.6ms preprocess, 219.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 237.5ms\n",
            "Speed: 8.6ms preprocess, 237.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 232.3ms\n",
            "Speed: 4.3ms preprocess, 232.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 244.3ms\n",
            "Speed: 6.8ms preprocess, 244.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 219.5ms\n",
            "Speed: 4.1ms preprocess, 219.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 279.2ms\n",
            "Speed: 8.5ms preprocess, 279.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 149.4ms\n",
            "Speed: 7.9ms preprocess, 149.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 145.2ms\n",
            "Speed: 5.9ms preprocess, 145.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 148.6ms\n",
            "Speed: 6.2ms preprocess, 148.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 153.8ms\n",
            "Speed: 5.9ms preprocess, 153.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 129.7ms\n",
            "Speed: 4.0ms preprocess, 129.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 134.6ms\n",
            "Speed: 3.9ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 148.9ms\n",
            "Speed: 4.7ms preprocess, 148.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 149.1ms\n",
            "Speed: 5.8ms preprocess, 149.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 146.1ms\n",
            "Speed: 4.0ms preprocess, 146.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 127.1ms\n",
            "Speed: 4.1ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 128.7ms\n",
            "Speed: 3.5ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 130.5ms\n",
            "Speed: 3.8ms preprocess, 130.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 137.5ms\n",
            "Speed: 4.9ms preprocess, 137.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 142.3ms\n",
            "Speed: 6.7ms preprocess, 142.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 suitcase, 1 bottle, 150.4ms\n",
            "Speed: 6.6ms preprocess, 150.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 143.0ms\n",
            "Speed: 4.9ms preprocess, 143.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 142.7ms\n",
            "Speed: 3.9ms preprocess, 142.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 137.9ms\n",
            "Speed: 5.7ms preprocess, 137.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 147.3ms\n",
            "Speed: 4.8ms preprocess, 147.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 152.6ms\n",
            "Speed: 4.0ms preprocess, 152.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 127.9ms\n",
            "Speed: 3.6ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 132.2ms\n",
            "Speed: 3.7ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 136.0ms\n",
            "Speed: 4.3ms preprocess, 136.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 132.0ms\n",
            "Speed: 6.7ms preprocess, 132.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 126.8ms\n",
            "Speed: 5.2ms preprocess, 126.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 125.0ms\n",
            "Speed: 4.6ms preprocess, 125.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 205.0ms\n",
            "Speed: 3.8ms preprocess, 205.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 220.2ms\n",
            "Speed: 4.4ms preprocess, 220.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 214.1ms\n",
            "Speed: 4.5ms preprocess, 214.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 228.8ms\n",
            "Speed: 4.2ms preprocess, 228.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 238.3ms\n",
            "Speed: 7.3ms preprocess, 238.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 222.9ms\n",
            "Speed: 4.4ms preprocess, 222.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 237.8ms\n",
            "Speed: 4.5ms preprocess, 237.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 138.3ms\n",
            "Speed: 4.2ms preprocess, 138.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 bottles, 136.5ms\n",
            "Speed: 6.6ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 125.7ms\n",
            "Speed: 8.8ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 124.8ms\n",
            "Speed: 3.8ms preprocess, 124.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 155.6ms\n",
            "Speed: 7.8ms preprocess, 155.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 148.7ms\n",
            "Speed: 4.1ms preprocess, 148.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 130.3ms\n",
            "Speed: 8.9ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 124.3ms\n",
            "Speed: 3.4ms preprocess, 124.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 122.6ms\n",
            "Speed: 4.3ms preprocess, 122.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 124.2ms\n",
            "Speed: 3.5ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 126.4ms\n",
            "Speed: 4.2ms preprocess, 126.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 124.2ms\n",
            "Speed: 3.8ms preprocess, 124.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 150.9ms\n",
            "Speed: 4.0ms preprocess, 150.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 140.7ms\n",
            "Speed: 4.1ms preprocess, 140.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 136.6ms\n",
            "Speed: 4.3ms preprocess, 136.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 178.1ms\n",
            "Speed: 5.8ms preprocess, 178.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 125.1ms\n",
            "Speed: 6.3ms preprocess, 125.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 140.8ms\n",
            "Speed: 7.4ms preprocess, 140.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 151.3ms\n",
            "Speed: 4.2ms preprocess, 151.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 146.5ms\n",
            "Speed: 3.9ms preprocess, 146.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 158.4ms\n",
            "Speed: 5.4ms preprocess, 158.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 144.2ms\n",
            "Speed: 7.1ms preprocess, 144.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 139.3ms\n",
            "Speed: 14.0ms preprocess, 139.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 166.8ms\n",
            "Speed: 4.3ms preprocess, 166.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 140.1ms\n",
            "Speed: 4.6ms preprocess, 140.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 142.2ms\n",
            "Speed: 4.3ms preprocess, 142.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 144.1ms\n",
            "Speed: 10.2ms preprocess, 144.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 132.9ms\n",
            "Speed: 4.1ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 125.3ms\n",
            "Speed: 3.9ms preprocess, 125.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 144.2ms\n",
            "Speed: 3.9ms preprocess, 144.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 157.1ms\n",
            "Speed: 3.8ms preprocess, 157.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 197.4ms\n",
            "Speed: 3.5ms preprocess, 197.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 197.4ms\n",
            "Speed: 4.4ms preprocess, 197.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 219.7ms\n",
            "Speed: 4.3ms preprocess, 219.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 233.1ms\n",
            "Speed: 4.2ms preprocess, 233.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 231.8ms\n",
            "Speed: 8.7ms preprocess, 231.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 225.3ms\n",
            "Speed: 4.5ms preprocess, 225.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 194.6ms\n",
            "Speed: 4.7ms preprocess, 194.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 215.3ms\n",
            "Speed: 3.7ms preprocess, 215.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 193.7ms\n",
            "Speed: 6.9ms preprocess, 193.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 203.3ms\n",
            "Speed: 3.6ms preprocess, 203.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 216.1ms\n",
            "Speed: 3.8ms preprocess, 216.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 232.3ms\n",
            "Speed: 4.2ms preprocess, 232.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 219.3ms\n",
            "Speed: 7.3ms preprocess, 219.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 212.0ms\n",
            "Speed: 8.4ms preprocess, 212.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 232.7ms\n",
            "Speed: 4.2ms preprocess, 232.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 240.3ms\n",
            "Speed: 4.2ms preprocess, 240.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 271.8ms\n",
            "Speed: 5.5ms preprocess, 271.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 217.6ms\n",
            "Speed: 5.9ms preprocess, 217.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 134.5ms\n",
            "Speed: 4.7ms preprocess, 134.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 145.7ms\n",
            "Speed: 4.4ms preprocess, 145.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 134.6ms\n",
            "Speed: 4.1ms preprocess, 134.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 143.1ms\n",
            "Speed: 4.5ms preprocess, 143.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 148.9ms\n",
            "Speed: 4.4ms preprocess, 148.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 142.5ms\n",
            "Speed: 4.2ms preprocess, 142.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 129.0ms\n",
            "Speed: 3.8ms preprocess, 129.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 131.8ms\n",
            "Speed: 3.5ms preprocess, 131.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 131.5ms\n",
            "Speed: 5.0ms preprocess, 131.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 147.6ms\n",
            "Speed: 4.6ms preprocess, 147.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 126.4ms\n",
            "Speed: 4.5ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 130.0ms\n",
            "Speed: 3.8ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 148.1ms\n",
            "Speed: 3.7ms preprocess, 148.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 139.9ms\n",
            "Speed: 4.3ms preprocess, 139.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 145.5ms\n",
            "Speed: 4.6ms preprocess, 145.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 154.5ms\n",
            "Speed: 4.6ms preprocess, 154.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 143.5ms\n",
            "Speed: 4.8ms preprocess, 143.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 137.1ms\n",
            "Speed: 7.8ms preprocess, 137.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 148.1ms\n",
            "Speed: 4.2ms preprocess, 148.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 151.7ms\n",
            "Speed: 5.4ms preprocess, 151.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 156.7ms\n",
            "Speed: 4.4ms preprocess, 156.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 161.9ms\n",
            "Speed: 4.1ms preprocess, 161.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 148.0ms\n",
            "Speed: 4.4ms preprocess, 148.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 152.8ms\n",
            "Speed: 4.6ms preprocess, 152.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 153.1ms\n",
            "Speed: 5.2ms preprocess, 153.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 159.1ms\n",
            "Speed: 4.2ms preprocess, 159.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 152.3ms\n",
            "Speed: 4.2ms preprocess, 152.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 170.4ms\n",
            "Speed: 4.8ms preprocess, 170.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 148.6ms\n",
            "Speed: 5.1ms preprocess, 148.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 142.0ms\n",
            "Speed: 4.7ms preprocess, 142.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 128.3ms\n",
            "Speed: 3.7ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 130.1ms\n",
            "Speed: 3.7ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 126.3ms\n",
            "Speed: 4.1ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 144.3ms\n",
            "Speed: 3.5ms preprocess, 144.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 127.1ms\n",
            "Speed: 3.6ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 140.7ms\n",
            "Speed: 3.6ms preprocess, 140.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 130.1ms\n",
            "Speed: 4.3ms preprocess, 130.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 145.6ms\n",
            "Speed: 3.8ms preprocess, 145.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 126.3ms\n",
            "Speed: 3.8ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 141.8ms\n",
            "Speed: 3.9ms preprocess, 141.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 129.6ms\n",
            "Speed: 4.1ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 133.8ms\n",
            "Speed: 3.7ms preprocess, 133.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 146.9ms\n",
            "Speed: 3.8ms preprocess, 146.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 151.8ms\n",
            "Speed: 4.4ms preprocess, 151.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 152.8ms\n",
            "Speed: 4.1ms preprocess, 152.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 169.1ms\n",
            "Speed: 4.1ms preprocess, 169.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 161.0ms\n",
            "Speed: 4.1ms preprocess, 161.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 156.4ms\n",
            "Speed: 5.0ms preprocess, 156.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 156.1ms\n",
            "Speed: 6.0ms preprocess, 156.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 149.2ms\n",
            "Speed: 4.1ms preprocess, 149.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 164.0ms\n",
            "Speed: 4.4ms preprocess, 164.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 159.2ms\n",
            "Speed: 4.5ms preprocess, 159.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 145.2ms\n",
            "Speed: 4.1ms preprocess, 145.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 157.3ms\n",
            "Speed: 4.2ms preprocess, 157.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 151.3ms\n",
            "Speed: 4.3ms preprocess, 151.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 144.3ms\n",
            "Speed: 4.2ms preprocess, 144.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 146.9ms\n",
            "Speed: 4.4ms preprocess, 146.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 153.1ms\n",
            "Speed: 10.0ms preprocess, 153.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 204.5ms\n",
            "Speed: 5.6ms preprocess, 204.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 210.7ms\n",
            "Speed: 3.9ms preprocess, 210.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 191.3ms\n",
            "Speed: 6.9ms preprocess, 191.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 200.0ms\n",
            "Speed: 3.6ms preprocess, 200.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 200.2ms\n",
            "Speed: 3.9ms preprocess, 200.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 193.6ms\n",
            "Speed: 3.8ms preprocess, 193.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 199.1ms\n",
            "Speed: 3.8ms preprocess, 199.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 205.5ms\n",
            "Speed: 3.5ms preprocess, 205.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 196.7ms\n",
            "Speed: 3.7ms preprocess, 196.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 196.9ms\n",
            "Speed: 3.7ms preprocess, 196.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 219.8ms\n",
            "Speed: 4.1ms preprocess, 219.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 217.5ms\n",
            "Speed: 4.6ms preprocess, 217.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 221.4ms\n",
            "Speed: 4.6ms preprocess, 221.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 238.5ms\n",
            "Speed: 4.7ms preprocess, 238.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 240.5ms\n",
            "Speed: 4.4ms preprocess, 240.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 217.7ms\n",
            "Speed: 6.3ms preprocess, 217.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 234.8ms\n",
            "Speed: 5.6ms preprocess, 234.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 227.9ms\n",
            "Speed: 4.4ms preprocess, 227.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 223.1ms\n",
            "Speed: 7.2ms preprocess, 223.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 219.9ms\n",
            "Speed: 7.3ms preprocess, 219.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 147.5ms\n",
            "Speed: 4.5ms preprocess, 147.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 156.5ms\n",
            "Speed: 4.3ms preprocess, 156.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 143.1ms\n",
            "Speed: 4.4ms preprocess, 143.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 144.0ms\n",
            "Speed: 4.5ms preprocess, 144.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 bottles, 144.4ms\n",
            "Speed: 4.5ms preprocess, 144.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 136.7ms\n",
            "Speed: 4.4ms preprocess, 136.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 140.2ms\n",
            "Speed: 4.7ms preprocess, 140.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 155.3ms\n",
            "Speed: 4.4ms preprocess, 155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 151.5ms\n",
            "Speed: 4.3ms preprocess, 151.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 152.8ms\n",
            "Speed: 5.1ms preprocess, 152.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 149.5ms\n",
            "Speed: 4.9ms preprocess, 149.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 146.6ms\n",
            "Speed: 4.5ms preprocess, 146.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 1 book, 141.8ms\n",
            "Speed: 4.0ms preprocess, 141.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 154.2ms\n",
            "Speed: 4.0ms preprocess, 154.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 162.3ms\n",
            "Speed: 4.6ms preprocess, 162.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 154.7ms\n",
            "Speed: 4.6ms preprocess, 154.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 155.9ms\n",
            "Speed: 4.7ms preprocess, 155.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 138.6ms\n",
            "Speed: 4.3ms preprocess, 138.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 152.6ms\n",
            "Speed: 4.3ms preprocess, 152.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 150.1ms\n",
            "Speed: 4.7ms preprocess, 150.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 126.4ms\n",
            "Speed: 3.8ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 130.4ms\n",
            "Speed: 3.9ms preprocess, 130.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 131.6ms\n",
            "Speed: 3.7ms preprocess, 131.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 129.6ms\n",
            "Speed: 3.8ms preprocess, 129.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 bottle, 134.9ms\n",
            "Speed: 3.6ms preprocess, 134.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 126.0ms\n",
            "Speed: 5.3ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 141.1ms\n",
            "Speed: 5.0ms preprocess, 141.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 128.9ms\n",
            "Speed: 3.7ms preprocess, 128.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 125.8ms\n",
            "Speed: 6.9ms preprocess, 125.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 126.8ms\n",
            "Speed: 3.8ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 149.6ms\n",
            "Speed: 4.5ms preprocess, 149.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 151.5ms\n",
            "Speed: 8.1ms preprocess, 151.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 146.9ms\n",
            "Speed: 4.8ms preprocess, 146.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 141.2ms\n",
            "Speed: 5.2ms preprocess, 141.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 224.5ms\n",
            "Speed: 8.4ms preprocess, 224.5ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 231.1ms\n",
            "Speed: 4.2ms preprocess, 231.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 200.9ms\n",
            "Speed: 3.7ms preprocess, 200.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 226.6ms\n",
            "Speed: 4.4ms preprocess, 226.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 237.6ms\n",
            "Speed: 8.3ms preprocess, 237.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 152.9ms\n",
            "Speed: 9.8ms preprocess, 152.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 133.4ms\n",
            "Speed: 4.4ms preprocess, 133.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 135.6ms\n",
            "Speed: 5.7ms preprocess, 135.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 141.5ms\n",
            "Speed: 5.2ms preprocess, 141.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.0ms\n",
            "Speed: 4.8ms preprocess, 147.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 129.3ms\n",
            "Speed: 5.9ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.1ms\n",
            "Speed: 4.4ms preprocess, 130.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 126.1ms\n",
            "Speed: 4.8ms preprocess, 126.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 136.7ms\n",
            "Speed: 4.1ms preprocess, 136.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 141.0ms\n",
            "Speed: 4.2ms preprocess, 141.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 132.2ms\n",
            "Speed: 5.2ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 124.4ms\n",
            "Speed: 3.8ms preprocess, 124.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.4ms\n",
            "Speed: 3.6ms preprocess, 143.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 129.7ms\n",
            "Speed: 4.9ms preprocess, 129.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.4ms\n",
            "Speed: 4.9ms preprocess, 143.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.5ms\n",
            "Speed: 6.4ms preprocess, 140.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 146.0ms\n",
            "Speed: 6.3ms preprocess, 146.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 212.6ms\n",
            "Speed: 4.4ms preprocess, 212.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 204.1ms\n",
            "Speed: 3.9ms preprocess, 204.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 221.3ms\n",
            "Speed: 5.2ms preprocess, 221.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 248.5ms\n",
            "Speed: 16.3ms preprocess, 248.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 229.8ms\n",
            "Speed: 4.3ms preprocess, 229.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 143.9ms\n",
            "Speed: 6.6ms preprocess, 143.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 146.0ms\n",
            "Speed: 4.6ms preprocess, 146.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 125.5ms\n",
            "Speed: 5.2ms preprocess, 125.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.7ms\n",
            "Speed: 4.0ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 150.9ms\n",
            "Speed: 5.3ms preprocess, 150.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 126.2ms\n",
            "Speed: 4.0ms preprocess, 126.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 133.2ms\n",
            "Speed: 3.7ms preprocess, 133.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 124.6ms\n",
            "Speed: 3.8ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 134.5ms\n",
            "Speed: 3.7ms preprocess, 134.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 141.0ms\n",
            "Speed: 4.0ms preprocess, 141.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 198.2ms\n",
            "Speed: 5.0ms preprocess, 198.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 153.8ms\n",
            "Speed: 4.6ms preprocess, 153.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 125.7ms\n",
            "Speed: 6.6ms preprocess, 125.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 126.8ms\n",
            "Speed: 3.7ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.2ms\n",
            "Speed: 3.5ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.8ms\n",
            "Speed: 4.1ms preprocess, 130.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 155.7ms\n",
            "Speed: 4.5ms preprocess, 155.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 200.4ms\n",
            "Speed: 3.9ms preprocess, 200.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 202.3ms\n",
            "Speed: 6.5ms preprocess, 202.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 223.2ms\n",
            "Speed: 3.7ms preprocess, 223.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 211.9ms\n",
            "Speed: 4.2ms preprocess, 211.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 213.2ms\n",
            "Speed: 7.9ms preprocess, 213.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.6ms\n",
            "Speed: 4.2ms preprocess, 137.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 135.3ms\n",
            "Speed: 4.3ms preprocess, 135.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 142.4ms\n",
            "Speed: 5.3ms preprocess, 142.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 141.4ms\n",
            "Speed: 4.5ms preprocess, 141.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 150.4ms\n",
            "Speed: 6.1ms preprocess, 150.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 134.9ms\n",
            "Speed: 4.5ms preprocess, 134.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 135.0ms\n",
            "Speed: 4.6ms preprocess, 135.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 125.6ms\n",
            "Speed: 4.6ms preprocess, 125.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 132.1ms\n",
            "Speed: 9.6ms preprocess, 132.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 129.3ms\n",
            "Speed: 4.1ms preprocess, 129.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 133.2ms\n",
            "Speed: 3.5ms preprocess, 133.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 150.0ms\n",
            "Speed: 6.0ms preprocess, 150.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 139.0ms\n",
            "Speed: 6.8ms preprocess, 139.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 140.6ms\n",
            "Speed: 4.1ms preprocess, 140.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 143.5ms\n",
            "Speed: 4.5ms preprocess, 143.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 134.3ms\n",
            "Speed: 6.2ms preprocess, 134.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 149.5ms\n",
            "Speed: 10.8ms preprocess, 149.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 192.5ms\n",
            "Speed: 7.9ms preprocess, 192.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 228.2ms\n",
            "Speed: 4.4ms preprocess, 228.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 196.8ms\n",
            "Speed: 3.9ms preprocess, 196.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 213.8ms\n",
            "Speed: 6.7ms preprocess, 213.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 231.7ms\n",
            "Speed: 6.7ms preprocess, 231.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 152.8ms\n",
            "Speed: 4.2ms preprocess, 152.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 138.4ms\n",
            "Speed: 5.7ms preprocess, 138.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 141.1ms\n",
            "Speed: 4.1ms preprocess, 141.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 147.0ms\n",
            "Speed: 4.3ms preprocess, 147.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 150.9ms\n",
            "Speed: 5.3ms preprocess, 150.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 155.0ms\n",
            "Speed: 5.8ms preprocess, 155.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 140.3ms\n",
            "Speed: 4.3ms preprocess, 140.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 149.1ms\n",
            "Speed: 4.3ms preprocess, 149.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 130.8ms\n",
            "Speed: 4.7ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 125.2ms\n",
            "Speed: 3.8ms preprocess, 125.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 127.0ms\n",
            "Speed: 3.6ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 126.6ms\n",
            "Speed: 3.7ms preprocess, 126.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 156.5ms\n",
            "Speed: 7.9ms preprocess, 156.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 146.0ms\n",
            "Speed: 5.6ms preprocess, 146.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 132.9ms\n",
            "Speed: 3.9ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 138.0ms\n",
            "Speed: 5.4ms preprocess, 138.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 140.5ms\n",
            "Speed: 4.4ms preprocess, 140.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 157.8ms\n",
            "Speed: 4.0ms preprocess, 157.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 153.0ms\n",
            "Speed: 5.3ms preprocess, 153.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 131.5ms\n",
            "Speed: 4.1ms preprocess, 131.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 212.9ms\n",
            "Speed: 3.7ms preprocess, 212.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 223.5ms\n",
            "Speed: 20.7ms preprocess, 223.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 214.2ms\n",
            "Speed: 7.8ms preprocess, 214.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 221.8ms\n",
            "Speed: 9.1ms preprocess, 221.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 217.6ms\n",
            "Speed: 3.8ms preprocess, 217.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 160.5ms\n",
            "Speed: 4.6ms preprocess, 160.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 129.7ms\n",
            "Speed: 7.5ms preprocess, 129.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 127.3ms\n",
            "Speed: 3.6ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 125.7ms\n",
            "Speed: 3.6ms preprocess, 125.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 125.2ms\n",
            "Speed: 10.8ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.8ms\n",
            "Speed: 3.6ms preprocess, 130.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 131.7ms\n",
            "Speed: 4.6ms preprocess, 131.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 127.4ms\n",
            "Speed: 4.4ms preprocess, 127.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 126.8ms\n",
            "Speed: 5.6ms preprocess, 126.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 148.7ms\n",
            "Speed: 7.1ms preprocess, 148.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 141.3ms\n",
            "Speed: 5.4ms preprocess, 141.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 142.5ms\n",
            "Speed: 4.5ms preprocess, 142.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 139.0ms\n",
            "Speed: 4.4ms preprocess, 139.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.1ms\n",
            "Speed: 5.1ms preprocess, 138.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.8ms\n",
            "Speed: 4.4ms preprocess, 138.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.9ms\n",
            "Speed: 4.8ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 142.5ms\n",
            "Speed: 3.9ms preprocess, 142.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 226.1ms\n",
            "Speed: 3.7ms preprocess, 226.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 198.8ms\n",
            "Speed: 3.8ms preprocess, 198.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 218.9ms\n",
            "Speed: 10.0ms preprocess, 218.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 218.4ms\n",
            "Speed: 15.1ms preprocess, 218.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 194.6ms\n",
            "Speed: 6.2ms preprocess, 194.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.6ms\n",
            "Speed: 3.8ms preprocess, 140.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 148.8ms\n",
            "Speed: 5.5ms preprocess, 148.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 139.1ms\n",
            "Speed: 5.0ms preprocess, 139.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 141.6ms\n",
            "Speed: 4.1ms preprocess, 141.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 144.1ms\n",
            "Speed: 4.0ms preprocess, 144.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 148.7ms\n",
            "Speed: 6.8ms preprocess, 148.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.4ms\n",
            "Speed: 3.8ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.9ms\n",
            "Speed: 3.6ms preprocess, 147.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.6ms\n",
            "Speed: 4.4ms preprocess, 143.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.9ms\n",
            "Speed: 5.3ms preprocess, 140.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.7ms\n",
            "Speed: 4.6ms preprocess, 140.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 145.3ms\n",
            "Speed: 7.3ms preprocess, 145.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 187.9ms\n",
            "Speed: 4.3ms preprocess, 187.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 145.5ms\n",
            "Speed: 4.9ms preprocess, 145.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 145.7ms\n",
            "Speed: 4.5ms preprocess, 145.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 129.6ms\n",
            "Speed: 3.5ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 192.3ms\n",
            "Speed: 3.5ms preprocess, 192.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 199.2ms\n",
            "Speed: 3.8ms preprocess, 199.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 198.2ms\n",
            "Speed: 3.8ms preprocess, 198.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 239.2ms\n",
            "Speed: 4.1ms preprocess, 239.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 216.6ms\n",
            "Speed: 10.2ms preprocess, 216.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 149.1ms\n",
            "Speed: 5.2ms preprocess, 149.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 apple, 2 donuts, 142.5ms\n",
            "Speed: 4.3ms preprocess, 142.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 145.7ms\n",
            "Speed: 4.8ms preprocess, 145.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 136.6ms\n",
            "Speed: 4.4ms preprocess, 136.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.5ms\n",
            "Speed: 4.4ms preprocess, 143.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.4ms\n",
            "Speed: 4.4ms preprocess, 138.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.0ms\n",
            "Speed: 8.2ms preprocess, 143.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.1ms\n",
            "Speed: 4.1ms preprocess, 137.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 127.7ms\n",
            "Speed: 4.5ms preprocess, 127.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 126.4ms\n",
            "Speed: 4.0ms preprocess, 126.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 127.8ms\n",
            "Speed: 3.8ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.0ms\n",
            "Speed: 4.7ms preprocess, 147.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 133.9ms\n",
            "Speed: 6.5ms preprocess, 133.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 151.7ms\n",
            "Speed: 4.3ms preprocess, 151.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 138.1ms\n",
            "Speed: 4.8ms preprocess, 138.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 136.3ms\n",
            "Speed: 6.2ms preprocess, 136.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 144.9ms\n",
            "Speed: 4.2ms preprocess, 144.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 138.9ms\n",
            "Speed: 5.3ms preprocess, 138.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 212.3ms\n",
            "Speed: 10.7ms preprocess, 212.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 199.3ms\n",
            "Speed: 4.0ms preprocess, 199.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 223.9ms\n",
            "Speed: 5.7ms preprocess, 223.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 215.0ms\n",
            "Speed: 6.8ms preprocess, 215.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 211.3ms\n",
            "Speed: 10.1ms preprocess, 211.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 219.0ms\n",
            "Speed: 8.0ms preprocess, 219.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 226.6ms\n",
            "Speed: 4.2ms preprocess, 226.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 228.5ms\n",
            "Speed: 5.5ms preprocess, 228.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 235.4ms\n",
            "Speed: 17.8ms preprocess, 235.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 151.9ms\n",
            "Speed: 5.2ms preprocess, 151.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 173.6ms\n",
            "Speed: 8.2ms preprocess, 173.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 142.7ms\n",
            "Speed: 5.1ms preprocess, 142.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 140.8ms\n",
            "Speed: 4.6ms preprocess, 140.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 145.7ms\n",
            "Speed: 5.9ms preprocess, 145.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 141.4ms\n",
            "Speed: 4.2ms preprocess, 141.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 126.4ms\n",
            "Speed: 3.7ms preprocess, 126.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 145.3ms\n",
            "Speed: 4.2ms preprocess, 145.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 139.5ms\n",
            "Speed: 4.0ms preprocess, 139.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.0ms\n",
            "Speed: 6.0ms preprocess, 140.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 145.9ms\n",
            "Speed: 6.4ms preprocess, 145.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 146.7ms\n",
            "Speed: 8.7ms preprocess, 146.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.3ms\n",
            "Speed: 4.0ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.1ms\n",
            "Speed: 3.8ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 124.4ms\n",
            "Speed: 4.1ms preprocess, 124.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 142.2ms\n",
            "Speed: 7.7ms preprocess, 142.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 141.0ms\n",
            "Speed: 4.4ms preprocess, 141.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 153.7ms\n",
            "Speed: 4.0ms preprocess, 153.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 214.3ms\n",
            "Speed: 6.6ms preprocess, 214.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 235.8ms\n",
            "Speed: 9.0ms preprocess, 235.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 212.5ms\n",
            "Speed: 4.2ms preprocess, 212.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 217.1ms\n",
            "Speed: 4.3ms preprocess, 217.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 216.4ms\n",
            "Speed: 4.0ms preprocess, 216.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 140.0ms\n",
            "Speed: 13.7ms preprocess, 140.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 145.7ms\n",
            "Speed: 6.6ms preprocess, 145.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 149.3ms\n",
            "Speed: 4.1ms preprocess, 149.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 143.6ms\n",
            "Speed: 4.3ms preprocess, 143.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 128.0ms\n",
            "Speed: 3.5ms preprocess, 128.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 124.2ms\n",
            "Speed: 3.7ms preprocess, 124.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 2 donuts, 144.5ms\n",
            "Speed: 4.1ms preprocess, 144.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 146.4ms\n",
            "Speed: 4.8ms preprocess, 146.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 154.8ms\n",
            "Speed: 4.0ms preprocess, 154.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 143.6ms\n",
            "Speed: 3.9ms preprocess, 143.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 144.1ms\n",
            "Speed: 4.0ms preprocess, 144.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 skateboard, 1 donut, 130.4ms\n",
            "Speed: 3.8ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 129.3ms\n",
            "Speed: 3.5ms preprocess, 129.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 127.3ms\n",
            "Speed: 4.9ms preprocess, 127.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 124.6ms\n",
            "Speed: 3.6ms preprocess, 124.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 126.7ms\n",
            "Speed: 13.6ms preprocess, 126.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 134.8ms\n",
            "Speed: 4.9ms preprocess, 134.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 201.9ms\n",
            "Speed: 3.8ms preprocess, 201.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 240.0ms\n",
            "Speed: 4.1ms preprocess, 240.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 229.4ms\n",
            "Speed: 4.2ms preprocess, 229.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 217.3ms\n",
            "Speed: 6.0ms preprocess, 217.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 243.9ms\n",
            "Speed: 8.3ms preprocess, 243.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 138.2ms\n",
            "Speed: 4.5ms preprocess, 138.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 151.7ms\n",
            "Speed: 4.7ms preprocess, 151.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 138.6ms\n",
            "Speed: 6.9ms preprocess, 138.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 158.7ms\n",
            "Speed: 4.5ms preprocess, 158.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 171.1ms\n",
            "Speed: 4.2ms preprocess, 171.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 132.7ms\n",
            "Speed: 4.6ms preprocess, 132.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 125.1ms\n",
            "Speed: 9.8ms preprocess, 125.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 129.5ms\n",
            "Speed: 3.8ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 127.5ms\n",
            "Speed: 6.4ms preprocess, 127.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 127.3ms\n",
            "Speed: 4.2ms preprocess, 127.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 131.6ms\n",
            "Speed: 3.5ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 123.4ms\n",
            "Speed: 4.5ms preprocess, 123.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 137.4ms\n",
            "Speed: 5.0ms preprocess, 137.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 151.9ms\n",
            "Speed: 3.9ms preprocess, 151.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 188.0ms\n",
            "Speed: 4.3ms preprocess, 188.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 136.7ms\n",
            "Speed: 7.2ms preprocess, 136.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 135.1ms\n",
            "Speed: 4.4ms preprocess, 135.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 218.6ms\n",
            "Speed: 7.2ms preprocess, 218.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 220.5ms\n",
            "Speed: 23.1ms preprocess, 220.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 217.1ms\n",
            "Speed: 4.3ms preprocess, 217.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 215.7ms\n",
            "Speed: 6.4ms preprocess, 215.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 228.7ms\n",
            "Speed: 7.4ms preprocess, 228.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 157.3ms\n",
            "Speed: 5.3ms preprocess, 157.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.4ms\n",
            "Speed: 6.8ms preprocess, 138.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 139.8ms\n",
            "Speed: 5.2ms preprocess, 139.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.9ms\n",
            "Speed: 4.5ms preprocess, 137.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 139.4ms\n",
            "Speed: 3.9ms preprocess, 139.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 154.1ms\n",
            "Speed: 4.9ms preprocess, 154.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.5ms\n",
            "Speed: 4.6ms preprocess, 147.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.0ms\n",
            "Speed: 3.9ms preprocess, 130.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 135.8ms\n",
            "Speed: 4.0ms preprocess, 135.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.8ms\n",
            "Speed: 4.6ms preprocess, 147.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 124.1ms\n",
            "Speed: 5.0ms preprocess, 124.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 125.4ms\n",
            "Speed: 4.9ms preprocess, 125.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.3ms\n",
            "Speed: 5.0ms preprocess, 137.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 135.1ms\n",
            "Speed: 4.4ms preprocess, 135.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 129.5ms\n",
            "Speed: 4.8ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 153.1ms\n",
            "Speed: 4.2ms preprocess, 153.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 236.3ms\n",
            "Speed: 5.0ms preprocess, 236.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 238.5ms\n",
            "Speed: 4.5ms preprocess, 238.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 220.8ms\n",
            "Speed: 5.0ms preprocess, 220.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 202.9ms\n",
            "Speed: 3.7ms preprocess, 202.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 230.7ms\n",
            "Speed: 4.1ms preprocess, 230.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 250.3ms\n",
            "Speed: 5.1ms preprocess, 250.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 154.2ms\n",
            "Speed: 6.0ms preprocess, 154.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 138.1ms\n",
            "Speed: 4.6ms preprocess, 138.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 139.8ms\n",
            "Speed: 4.6ms preprocess, 139.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 128.5ms\n",
            "Speed: 4.4ms preprocess, 128.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 129.1ms\n",
            "Speed: 3.8ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 132.9ms\n",
            "Speed: 4.4ms preprocess, 132.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.5ms\n",
            "Speed: 16.5ms preprocess, 137.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 141.4ms\n",
            "Speed: 5.6ms preprocess, 141.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 134.8ms\n",
            "Speed: 4.4ms preprocess, 134.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 135.2ms\n",
            "Speed: 4.3ms preprocess, 135.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 142.6ms\n",
            "Speed: 5.3ms preprocess, 142.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 146.8ms\n",
            "Speed: 4.2ms preprocess, 146.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 151.0ms\n",
            "Speed: 4.1ms preprocess, 151.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 135.0ms\n",
            "Speed: 3.9ms preprocess, 135.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 127.4ms\n",
            "Speed: 5.4ms preprocess, 127.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 135.4ms\n",
            "Speed: 3.9ms preprocess, 135.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 126.3ms\n",
            "Speed: 4.2ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 142.0ms\n",
            "Speed: 4.1ms preprocess, 142.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 215.2ms\n",
            "Speed: 4.1ms preprocess, 215.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 237.8ms\n",
            "Speed: 9.5ms preprocess, 237.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 225.3ms\n",
            "Speed: 7.8ms preprocess, 225.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 209.3ms\n",
            "Speed: 11.5ms preprocess, 209.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 225.8ms\n",
            "Speed: 5.7ms preprocess, 225.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 237.9ms\n",
            "Speed: 7.4ms preprocess, 237.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 146.2ms\n",
            "Speed: 4.4ms preprocess, 146.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 128.5ms\n",
            "Speed: 3.8ms preprocess, 128.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 135.0ms\n",
            "Speed: 4.7ms preprocess, 135.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 136.6ms\n",
            "Speed: 4.1ms preprocess, 136.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 135.9ms\n",
            "Speed: 4.3ms preprocess, 135.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 137.9ms\n",
            "Speed: 5.7ms preprocess, 137.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 136.0ms\n",
            "Speed: 4.5ms preprocess, 136.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 159.0ms\n",
            "Speed: 8.3ms preprocess, 159.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 133.4ms\n",
            "Speed: 3.8ms preprocess, 133.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 130.4ms\n",
            "Speed: 4.5ms preprocess, 130.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 126.6ms\n",
            "Speed: 4.0ms preprocess, 126.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 148.5ms\n",
            "Speed: 5.2ms preprocess, 148.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 162.7ms\n",
            "Speed: 4.4ms preprocess, 162.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 130.7ms\n",
            "Speed: 4.0ms preprocess, 130.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 131.6ms\n",
            "Speed: 4.8ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 130.6ms\n",
            "Speed: 5.2ms preprocess, 130.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 2 donuts, 125.0ms\n",
            "Speed: 3.8ms preprocess, 125.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 2 donuts, 217.2ms\n",
            "Speed: 5.4ms preprocess, 217.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 2 donuts, 221.1ms\n",
            "Speed: 9.0ms preprocess, 221.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 1 donut, 211.1ms\n",
            "Speed: 3.7ms preprocess, 211.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 2 donuts, 216.7ms\n",
            "Speed: 3.5ms preprocess, 216.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 2 donuts, 200.8ms\n",
            "Speed: 3.8ms preprocess, 200.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 2 donuts, 124.1ms\n",
            "Speed: 4.0ms preprocess, 124.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 1 donut, 126.3ms\n",
            "Speed: 4.0ms preprocess, 126.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 1 donut, 148.2ms\n",
            "Speed: 4.0ms preprocess, 148.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 1 bottle, 1 donut, 147.7ms\n",
            "Speed: 5.7ms preprocess, 147.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 138.8ms\n",
            "Speed: 5.1ms preprocess, 138.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 148.3ms\n",
            "Speed: 5.1ms preprocess, 148.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 137.7ms\n",
            "Speed: 4.5ms preprocess, 137.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 149.4ms\n",
            "Speed: 5.4ms preprocess, 149.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 126.1ms\n",
            "Speed: 4.7ms preprocess, 126.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 126.1ms\n",
            "Speed: 4.2ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 131.2ms\n",
            "Speed: 4.8ms preprocess, 131.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 134.0ms\n",
            "Speed: 5.8ms preprocess, 134.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 134.7ms\n",
            "Speed: 4.5ms preprocess, 134.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 2 donuts, 149.1ms\n",
            "Speed: 6.0ms preprocess, 149.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 124.5ms\n",
            "Speed: 3.8ms preprocess, 124.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 130.6ms\n",
            "Speed: 4.3ms preprocess, 130.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 147.6ms\n",
            "Speed: 4.6ms preprocess, 147.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 143.1ms\n",
            "Speed: 7.0ms preprocess, 143.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 140.0ms\n",
            "Speed: 11.1ms preprocess, 140.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 184.1ms\n",
            "Speed: 4.4ms preprocess, 184.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 134.7ms\n",
            "Speed: 5.1ms preprocess, 134.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 127.8ms\n",
            "Speed: 5.1ms preprocess, 127.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 126.0ms\n",
            "Speed: 3.7ms preprocess, 126.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 handbag, 194.9ms\n",
            "Speed: 3.7ms preprocess, 194.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 189.7ms\n",
            "Speed: 6.5ms preprocess, 189.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 209.1ms\n",
            "Speed: 3.8ms preprocess, 209.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 215.6ms\n",
            "Speed: 4.2ms preprocess, 215.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 223.7ms\n",
            "Speed: 7.1ms preprocess, 223.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 226.9ms\n",
            "Speed: 4.3ms preprocess, 226.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 237.8ms\n",
            "Speed: 4.3ms preprocess, 237.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 225.6ms\n",
            "Speed: 14.2ms preprocess, 225.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 179.6ms\n",
            "Speed: 6.2ms preprocess, 179.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 140.1ms\n",
            "Speed: 4.5ms preprocess, 140.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 backpacks, 4 donuts, 138.2ms\n",
            "Speed: 4.7ms preprocess, 138.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 1 refrigerator, 123.9ms\n",
            "Speed: 3.7ms preprocess, 123.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 1 refrigerator, 128.1ms\n",
            "Speed: 3.9ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 1 refrigerator, 127.7ms\n",
            "Speed: 7.9ms preprocess, 127.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 1 refrigerator, 124.3ms\n",
            "Speed: 4.8ms preprocess, 124.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 1 refrigerator, 138.4ms\n",
            "Speed: 3.6ms preprocess, 138.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 1 refrigerator, 139.6ms\n",
            "Speed: 8.0ms preprocess, 139.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 2 donuts, 138.8ms\n",
            "Speed: 4.9ms preprocess, 138.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 126.4ms\n",
            "Speed: 4.1ms preprocess, 126.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 1 refrigerator, 126.3ms\n",
            "Speed: 4.0ms preprocess, 126.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 1 refrigerator, 126.1ms\n",
            "Speed: 4.5ms preprocess, 126.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 130.4ms\n",
            "Speed: 3.8ms preprocess, 130.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 122.6ms\n",
            "Speed: 3.5ms preprocess, 122.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 127.9ms\n",
            "Speed: 3.5ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 153.0ms\n",
            "Speed: 3.9ms preprocess, 153.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 137.9ms\n",
            "Speed: 6.3ms preprocess, 137.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 144.6ms\n",
            "Speed: 4.1ms preprocess, 144.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 149.5ms\n",
            "Speed: 4.8ms preprocess, 149.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 146.4ms\n",
            "Speed: 4.2ms preprocess, 146.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 151.7ms\n",
            "Speed: 4.4ms preprocess, 151.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 134.1ms\n",
            "Speed: 4.5ms preprocess, 134.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 138.0ms\n",
            "Speed: 4.3ms preprocess, 138.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 136.9ms\n",
            "Speed: 4.1ms preprocess, 136.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 143.4ms\n",
            "Speed: 5.6ms preprocess, 143.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 198.2ms\n",
            "Speed: 4.6ms preprocess, 198.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 234.3ms\n",
            "Speed: 13.0ms preprocess, 234.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 242.3ms\n",
            "Speed: 4.4ms preprocess, 242.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 218.2ms\n",
            "Speed: 6.8ms preprocess, 218.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 214.1ms\n",
            "Speed: 4.1ms preprocess, 214.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 2167.1ms\n",
            "Speed: 6.7ms preprocess, 2167.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 136.2ms\n",
            "Speed: 3.9ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 126.6ms\n",
            "Speed: 3.7ms preprocess, 126.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 140.7ms\n",
            "Speed: 4.1ms preprocess, 140.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 138.3ms\n",
            "Speed: 4.2ms preprocess, 138.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 142.4ms\n",
            "Speed: 4.8ms preprocess, 142.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 143.0ms\n",
            "Speed: 4.0ms preprocess, 143.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 139.9ms\n",
            "Speed: 4.3ms preprocess, 139.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 156.0ms\n",
            "Speed: 4.3ms preprocess, 156.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 142.1ms\n",
            "Speed: 4.1ms preprocess, 142.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 140.1ms\n",
            "Speed: 4.2ms preprocess, 140.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 141.9ms\n",
            "Speed: 7.2ms preprocess, 141.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 135.8ms\n",
            "Speed: 4.5ms preprocess, 135.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.5ms\n",
            "Speed: 4.0ms preprocess, 140.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.9ms\n",
            "Speed: 5.8ms preprocess, 138.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 140.7ms\n",
            "Speed: 4.5ms preprocess, 140.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 134.3ms\n",
            "Speed: 11.5ms preprocess, 134.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 203.7ms\n",
            "Speed: 4.1ms preprocess, 203.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 212.6ms\n",
            "Speed: 9.8ms preprocess, 212.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 213.9ms\n",
            "Speed: 7.3ms preprocess, 213.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 220.1ms\n",
            "Speed: 4.3ms preprocess, 220.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 192.4ms\n",
            "Speed: 4.3ms preprocess, 192.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 123.3ms\n",
            "Speed: 3.9ms preprocess, 123.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 128.3ms\n",
            "Speed: 6.2ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 137.6ms\n",
            "Speed: 6.6ms preprocess, 137.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 144.8ms\n",
            "Speed: 4.5ms preprocess, 144.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 135.5ms\n",
            "Speed: 5.8ms preprocess, 135.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 137.8ms\n",
            "Speed: 4.2ms preprocess, 137.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 134.7ms\n",
            "Speed: 4.6ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 129.0ms\n",
            "Speed: 4.3ms preprocess, 129.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 128.0ms\n",
            "Speed: 4.0ms preprocess, 128.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 134.2ms\n",
            "Speed: 6.5ms preprocess, 134.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 127.3ms\n",
            "Speed: 5.4ms preprocess, 127.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 128.9ms\n",
            "Speed: 3.9ms preprocess, 128.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 127.3ms\n",
            "Speed: 3.8ms preprocess, 127.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 145.0ms\n",
            "Speed: 16.0ms preprocess, 145.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 156.3ms\n",
            "Speed: 4.4ms preprocess, 156.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 133.0ms\n",
            "Speed: 5.3ms preprocess, 133.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 2 donuts, 197.8ms\n",
            "Speed: 4.2ms preprocess, 197.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 200.3ms\n",
            "Speed: 3.7ms preprocess, 200.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 216.5ms\n",
            "Speed: 4.1ms preprocess, 216.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 214.5ms\n",
            "Speed: 5.0ms preprocess, 214.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 209.6ms\n",
            "Speed: 4.3ms preprocess, 209.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.6ms\n",
            "Speed: 15.6ms preprocess, 138.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 137.8ms\n",
            "Speed: 17.5ms preprocess, 137.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 132.1ms\n",
            "Speed: 6.9ms preprocess, 132.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 139.7ms\n",
            "Speed: 4.2ms preprocess, 139.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 136.6ms\n",
            "Speed: 5.1ms preprocess, 136.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.8ms\n",
            "Speed: 4.8ms preprocess, 147.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.9ms\n",
            "Speed: 4.2ms preprocess, 143.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 142.6ms\n",
            "Speed: 5.2ms preprocess, 142.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 126.5ms\n",
            "Speed: 10.5ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 2 donuts, 153.0ms\n",
            "Speed: 3.7ms preprocess, 153.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 2 donuts, 138.9ms\n",
            "Speed: 4.8ms preprocess, 138.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 2 donuts, 141.0ms\n",
            "Speed: 4.3ms preprocess, 141.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 136.3ms\n",
            "Speed: 4.3ms preprocess, 136.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 130.2ms\n",
            "Speed: 8.3ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 148.5ms\n",
            "Speed: 5.7ms preprocess, 148.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 138.6ms\n",
            "Speed: 4.6ms preprocess, 138.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 322.8ms\n",
            "Speed: 4.2ms preprocess, 322.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 204.0ms\n",
            "Speed: 7.0ms preprocess, 204.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 199.6ms\n",
            "Speed: 3.7ms preprocess, 199.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 225.1ms\n",
            "Speed: 4.6ms preprocess, 225.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 215.2ms\n",
            "Speed: 4.7ms preprocess, 215.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 141.3ms\n",
            "Speed: 4.2ms preprocess, 141.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 156.0ms\n",
            "Speed: 4.0ms preprocess, 156.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 132.9ms\n",
            "Speed: 4.0ms preprocess, 132.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 126.5ms\n",
            "Speed: 4.5ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 136.8ms\n",
            "Speed: 10.9ms preprocess, 136.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 138.2ms\n",
            "Speed: 5.4ms preprocess, 138.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 141.9ms\n",
            "Speed: 4.5ms preprocess, 141.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 132.5ms\n",
            "Speed: 4.5ms preprocess, 132.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 127.9ms\n",
            "Speed: 3.9ms preprocess, 127.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 145.2ms\n",
            "Speed: 4.1ms preprocess, 145.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 142.2ms\n",
            "Speed: 4.8ms preprocess, 142.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 150.6ms\n",
            "Speed: 4.6ms preprocess, 150.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 139.3ms\n",
            "Speed: 4.4ms preprocess, 139.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 130.5ms\n",
            "Speed: 6.3ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 135.6ms\n",
            "Speed: 5.2ms preprocess, 135.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 142.1ms\n",
            "Speed: 4.3ms preprocess, 142.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 221.2ms\n",
            "Speed: 4.3ms preprocess, 221.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 237.5ms\n",
            "Speed: 4.5ms preprocess, 237.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 214.5ms\n",
            "Speed: 4.2ms preprocess, 214.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 242.6ms\n",
            "Speed: 6.6ms preprocess, 242.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 223.0ms\n",
            "Speed: 4.3ms preprocess, 223.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 144.1ms\n",
            "Speed: 4.3ms preprocess, 144.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 138.2ms\n",
            "Speed: 4.5ms preprocess, 138.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 148.1ms\n",
            "Speed: 4.6ms preprocess, 148.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 140.5ms\n",
            "Speed: 7.7ms preprocess, 140.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 149.4ms\n",
            "Speed: 5.0ms preprocess, 149.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 139.6ms\n",
            "Speed: 5.2ms preprocess, 139.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 139.0ms\n",
            "Speed: 4.6ms preprocess, 139.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 138.8ms\n",
            "Speed: 4.1ms preprocess, 138.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 143.0ms\n",
            "Speed: 4.4ms preprocess, 143.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 142.7ms\n",
            "Speed: 4.4ms preprocess, 142.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 142.6ms\n",
            "Speed: 4.0ms preprocess, 142.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 129.2ms\n",
            "Speed: 6.7ms preprocess, 129.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 127.8ms\n",
            "Speed: 6.7ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 144.1ms\n",
            "Speed: 5.7ms preprocess, 144.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 138.8ms\n",
            "Speed: 4.0ms preprocess, 138.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 143.3ms\n",
            "Speed: 4.0ms preprocess, 143.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 bottle, 1 donut, 223.3ms\n",
            "Speed: 4.2ms preprocess, 223.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 216.6ms\n",
            "Speed: 6.5ms preprocess, 216.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 1 donut, 222.0ms\n",
            "Speed: 4.1ms preprocess, 222.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 207.6ms\n",
            "Speed: 9.6ms preprocess, 207.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 237.0ms\n",
            "Speed: 3.7ms preprocess, 237.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 149.2ms\n",
            "Speed: 5.2ms preprocess, 149.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 145.6ms\n",
            "Speed: 5.6ms preprocess, 145.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 143.5ms\n",
            "Speed: 4.5ms preprocess, 143.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 142.9ms\n",
            "Speed: 6.3ms preprocess, 142.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 135.5ms\n",
            "Speed: 4.5ms preprocess, 135.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 bottles, 2 donuts, 158.6ms\n",
            "Speed: 5.0ms preprocess, 158.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 141.4ms\n",
            "Speed: 4.1ms preprocess, 141.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 158.8ms\n",
            "Speed: 4.0ms preprocess, 158.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 139.9ms\n",
            "Speed: 4.5ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 143.6ms\n",
            "Speed: 5.9ms preprocess, 143.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 141.8ms\n",
            "Speed: 4.0ms preprocess, 141.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 141.3ms\n",
            "Speed: 4.4ms preprocess, 141.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 152.6ms\n",
            "Speed: 4.7ms preprocess, 152.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 139.9ms\n",
            "Speed: 4.7ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 142.9ms\n",
            "Speed: 4.2ms preprocess, 142.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 138.8ms\n",
            "Speed: 4.4ms preprocess, 138.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 141.0ms\n",
            "Speed: 4.8ms preprocess, 141.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 148.2ms\n",
            "Speed: 4.9ms preprocess, 148.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 124.9ms\n",
            "Speed: 3.7ms preprocess, 124.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 129.2ms\n",
            "Speed: 3.5ms preprocess, 129.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 143.1ms\n",
            "Speed: 3.9ms preprocess, 143.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 221.5ms\n",
            "Speed: 4.3ms preprocess, 221.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 233.2ms\n",
            "Speed: 4.4ms preprocess, 233.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 228.0ms\n",
            "Speed: 4.4ms preprocess, 228.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 215.7ms\n",
            "Speed: 5.4ms preprocess, 215.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 218.4ms\n",
            "Speed: 4.0ms preprocess, 218.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 235.0ms\n",
            "Speed: 9.6ms preprocess, 235.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 248.9ms\n",
            "Speed: 4.7ms preprocess, 248.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 231.3ms\n",
            "Speed: 4.2ms preprocess, 231.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 149.0ms\n",
            "Speed: 4.3ms preprocess, 149.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 150.3ms\n",
            "Speed: 4.2ms preprocess, 150.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 144.9ms\n",
            "Speed: 4.1ms preprocess, 144.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 150.2ms\n",
            "Speed: 4.0ms preprocess, 150.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 140.0ms\n",
            "Speed: 3.9ms preprocess, 140.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 136.2ms\n",
            "Speed: 4.7ms preprocess, 136.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 3 donuts, 122.7ms\n",
            "Speed: 3.8ms preprocess, 122.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 123.4ms\n",
            "Speed: 4.3ms preprocess, 123.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 133.0ms\n",
            "Speed: 4.4ms preprocess, 133.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 152.9ms\n",
            "Speed: 3.7ms preprocess, 152.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 128.8ms\n",
            "Speed: 4.9ms preprocess, 128.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 147.9ms\n",
            "Speed: 4.5ms preprocess, 147.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 137.5ms\n",
            "Speed: 6.2ms preprocess, 137.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 143.7ms\n",
            "Speed: 7.2ms preprocess, 143.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 154.5ms\n",
            "Speed: 6.2ms preprocess, 154.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 137.4ms\n",
            "Speed: 4.6ms preprocess, 137.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 4 donuts, 133.2ms\n",
            "Speed: 4.4ms preprocess, 133.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 128.6ms\n",
            "Speed: 4.4ms preprocess, 128.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 127.7ms\n",
            "Speed: 4.1ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 236.3ms\n",
            "Speed: 8.2ms preprocess, 236.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 271.3ms\n",
            "Speed: 4.2ms preprocess, 271.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 197.8ms\n",
            "Speed: 4.0ms preprocess, 197.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 200.3ms\n",
            "Speed: 4.9ms preprocess, 200.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 214.9ms\n",
            "Speed: 3.8ms preprocess, 214.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 218.6ms\n",
            "Speed: 4.1ms preprocess, 218.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 137.3ms\n",
            "Speed: 5.5ms preprocess, 137.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 136.9ms\n",
            "Speed: 4.2ms preprocess, 136.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 135.3ms\n",
            "Speed: 3.8ms preprocess, 135.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 141.6ms\n",
            "Speed: 7.0ms preprocess, 141.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 141.3ms\n",
            "Speed: 5.4ms preprocess, 141.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 134.6ms\n",
            "Speed: 5.2ms preprocess, 134.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 145.7ms\n",
            "Speed: 5.1ms preprocess, 145.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 154.1ms\n",
            "Speed: 5.0ms preprocess, 154.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 144.3ms\n",
            "Speed: 7.9ms preprocess, 144.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 134.8ms\n",
            "Speed: 6.0ms preprocess, 134.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 135.8ms\n",
            "Speed: 5.5ms preprocess, 135.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 145.0ms\n",
            "Speed: 6.9ms preprocess, 145.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.6ms\n",
            "Speed: 4.2ms preprocess, 140.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 145.0ms\n",
            "Speed: 4.6ms preprocess, 145.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.4ms\n",
            "Speed: 6.1ms preprocess, 138.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 159.7ms\n",
            "Speed: 5.6ms preprocess, 159.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 200.3ms\n",
            "Speed: 6.6ms preprocess, 200.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 231.1ms\n",
            "Speed: 5.2ms preprocess, 231.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 226.6ms\n",
            "Speed: 7.3ms preprocess, 226.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 241.1ms\n",
            "Speed: 4.3ms preprocess, 241.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.1ms\n",
            "Speed: 4.3ms preprocess, 137.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 154.2ms\n",
            "Speed: 4.1ms preprocess, 154.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 142.2ms\n",
            "Speed: 4.8ms preprocess, 142.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.4ms\n",
            "Speed: 3.9ms preprocess, 128.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 125.5ms\n",
            "Speed: 4.5ms preprocess, 125.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 127.7ms\n",
            "Speed: 4.5ms preprocess, 127.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 127.1ms\n",
            "Speed: 7.8ms preprocess, 127.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.2ms\n",
            "Speed: 4.1ms preprocess, 138.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 134.0ms\n",
            "Speed: 4.6ms preprocess, 134.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.7ms\n",
            "Speed: 3.6ms preprocess, 128.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.4ms\n",
            "Speed: 6.1ms preprocess, 137.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 142.8ms\n",
            "Speed: 3.9ms preprocess, 142.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 157.3ms\n",
            "Speed: 5.0ms preprocess, 157.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 141.5ms\n",
            "Speed: 5.5ms preprocess, 141.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.9ms\n",
            "Speed: 4.5ms preprocess, 147.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.4ms\n",
            "Speed: 8.0ms preprocess, 147.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 247.9ms\n",
            "Speed: 3.7ms preprocess, 247.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 228.8ms\n",
            "Speed: 5.1ms preprocess, 228.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 199.0ms\n",
            "Speed: 3.7ms preprocess, 199.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 225.9ms\n",
            "Speed: 4.1ms preprocess, 225.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 216.4ms\n",
            "Speed: 4.0ms preprocess, 216.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 220.6ms\n",
            "Speed: 9.3ms preprocess, 220.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 144.9ms\n",
            "Speed: 6.0ms preprocess, 144.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 148.8ms\n",
            "Speed: 4.2ms preprocess, 148.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 145.9ms\n",
            "Speed: 4.4ms preprocess, 145.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 144.3ms\n",
            "Speed: 6.3ms preprocess, 144.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 144.9ms\n",
            "Speed: 4.3ms preprocess, 144.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 131.4ms\n",
            "Speed: 7.1ms preprocess, 131.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.3ms\n",
            "Speed: 3.7ms preprocess, 130.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 149.4ms\n",
            "Speed: 4.8ms preprocess, 149.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 141.9ms\n",
            "Speed: 4.7ms preprocess, 141.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 133.6ms\n",
            "Speed: 8.4ms preprocess, 133.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 128.4ms\n",
            "Speed: 3.7ms preprocess, 128.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 126.5ms\n",
            "Speed: 4.4ms preprocess, 126.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 135.0ms\n",
            "Speed: 4.2ms preprocess, 135.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 142.8ms\n",
            "Speed: 4.5ms preprocess, 142.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 216.9ms\n",
            "Speed: 3.9ms preprocess, 216.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 222.4ms\n",
            "Speed: 8.2ms preprocess, 222.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 231.9ms\n",
            "Speed: 4.3ms preprocess, 231.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 247.7ms\n",
            "Speed: 5.7ms preprocess, 247.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 142.8ms\n",
            "Speed: 4.2ms preprocess, 142.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 3 persons, 3 donuts, 141.6ms\n",
            "Speed: 5.2ms preprocess, 141.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 143.6ms\n",
            "Speed: 7.9ms preprocess, 143.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 145.5ms\n",
            "Speed: 5.2ms preprocess, 145.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 139.9ms\n",
            "Speed: 4.1ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 135.3ms\n",
            "Speed: 4.2ms preprocess, 135.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 139.7ms\n",
            "Speed: 3.7ms preprocess, 139.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 148.1ms\n",
            "Speed: 4.6ms preprocess, 148.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 149.9ms\n",
            "Speed: 5.3ms preprocess, 149.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 145.7ms\n",
            "Speed: 4.2ms preprocess, 145.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 126.3ms\n",
            "Speed: 8.0ms preprocess, 126.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 137.9ms\n",
            "Speed: 4.0ms preprocess, 137.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.4ms\n",
            "Speed: 7.3ms preprocess, 143.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.5ms\n",
            "Speed: 4.6ms preprocess, 143.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.9ms\n",
            "Speed: 5.3ms preprocess, 128.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 153.9ms\n",
            "Speed: 5.7ms preprocess, 153.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 241.3ms\n",
            "Speed: 4.2ms preprocess, 241.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 237.3ms\n",
            "Speed: 4.9ms preprocess, 237.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 325.0ms\n",
            "Speed: 3.8ms preprocess, 325.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 228.8ms\n",
            "Speed: 10.2ms preprocess, 228.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 226.0ms\n",
            "Speed: 4.4ms preprocess, 226.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.9ms\n",
            "Speed: 3.9ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.2ms\n",
            "Speed: 3.8ms preprocess, 128.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.9ms\n",
            "Speed: 4.3ms preprocess, 137.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 270.6ms\n",
            "Speed: 8.0ms preprocess, 270.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 149.3ms\n",
            "Speed: 5.2ms preprocess, 149.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 144.5ms\n",
            "Speed: 5.9ms preprocess, 144.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 144.6ms\n",
            "Speed: 6.2ms preprocess, 144.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.8ms\n",
            "Speed: 9.0ms preprocess, 143.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 142.4ms\n",
            "Speed: 6.0ms preprocess, 142.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 139.1ms\n",
            "Speed: 4.3ms preprocess, 139.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 153.9ms\n",
            "Speed: 6.0ms preprocess, 153.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 151.3ms\n",
            "Speed: 8.1ms preprocess, 151.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 143.2ms\n",
            "Speed: 5.9ms preprocess, 143.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.5ms\n",
            "Speed: 4.2ms preprocess, 140.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 211.9ms\n",
            "Speed: 3.9ms preprocess, 211.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 218.0ms\n",
            "Speed: 3.7ms preprocess, 218.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 226.3ms\n",
            "Speed: 4.3ms preprocess, 226.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 233.8ms\n",
            "Speed: 4.3ms preprocess, 233.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 238.8ms\n",
            "Speed: 4.3ms preprocess, 238.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 163.5ms\n",
            "Speed: 4.2ms preprocess, 163.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 131.2ms\n",
            "Speed: 3.7ms preprocess, 131.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 124.1ms\n",
            "Speed: 6.2ms preprocess, 124.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 140.1ms\n",
            "Speed: 5.4ms preprocess, 140.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 139.9ms\n",
            "Speed: 5.6ms preprocess, 139.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.9ms\n",
            "Speed: 4.8ms preprocess, 147.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 138.6ms\n",
            "Speed: 3.6ms preprocess, 138.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 133.4ms\n",
            "Speed: 6.7ms preprocess, 133.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 167.4ms\n",
            "Speed: 4.6ms preprocess, 167.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 132.8ms\n",
            "Speed: 4.6ms preprocess, 132.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 146.1ms\n",
            "Speed: 4.9ms preprocess, 146.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 149.5ms\n",
            "Speed: 5.8ms preprocess, 149.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 148.2ms\n",
            "Speed: 4.4ms preprocess, 148.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 148.9ms\n",
            "Speed: 6.5ms preprocess, 148.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 146.1ms\n",
            "Speed: 5.1ms preprocess, 146.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 151.6ms\n",
            "Speed: 4.3ms preprocess, 151.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 260.3ms\n",
            "Speed: 4.6ms preprocess, 260.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 245.1ms\n",
            "Speed: 4.5ms preprocess, 245.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 247.8ms\n",
            "Speed: 8.7ms preprocess, 247.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 254.2ms\n",
            "Speed: 4.2ms preprocess, 254.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 259.0ms\n",
            "Speed: 9.6ms preprocess, 259.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 165.2ms\n",
            "Speed: 9.8ms preprocess, 165.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 157.8ms\n",
            "Speed: 4.5ms preprocess, 157.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 165.9ms\n",
            "Speed: 5.4ms preprocess, 165.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 160.8ms\n",
            "Speed: 4.3ms preprocess, 160.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 168.4ms\n",
            "Speed: 4.5ms preprocess, 168.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 162.6ms\n",
            "Speed: 4.2ms preprocess, 162.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.2ms\n",
            "Speed: 5.0ms preprocess, 147.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 147.6ms\n",
            "Speed: 10.8ms preprocess, 147.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 167.1ms\n",
            "Speed: 4.4ms preprocess, 167.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 153.0ms\n",
            "Speed: 4.5ms preprocess, 153.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 160.5ms\n",
            "Speed: 5.0ms preprocess, 160.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 164.5ms\n",
            "Speed: 4.5ms preprocess, 164.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 155.5ms\n",
            "Speed: 4.2ms preprocess, 155.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 143.1ms\n",
            "Speed: 4.8ms preprocess, 143.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 2 donuts, 135.4ms\n",
            "Speed: 5.0ms preprocess, 135.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 2 donuts, 251.9ms\n",
            "Speed: 10.5ms preprocess, 251.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 2 donuts, 250.5ms\n",
            "Speed: 7.6ms preprocess, 250.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 2 donuts, 222.1ms\n",
            "Speed: 4.3ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 2 donuts, 233.5ms\n",
            "Speed: 5.0ms preprocess, 233.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 2 donuts, 239.4ms\n",
            "Speed: 6.2ms preprocess, 239.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 2 donuts, 145.4ms\n",
            "Speed: 4.8ms preprocess, 145.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 149.1ms\n",
            "Speed: 4.9ms preprocess, 149.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 141.4ms\n",
            "Speed: 4.1ms preprocess, 141.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 149.4ms\n",
            "Speed: 7.1ms preprocess, 149.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 151.8ms\n",
            "Speed: 5.6ms preprocess, 151.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 160.4ms\n",
            "Speed: 5.6ms preprocess, 160.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 174.2ms\n",
            "Speed: 4.5ms preprocess, 174.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 164.8ms\n",
            "Speed: 12.2ms preprocess, 164.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 130.0ms\n",
            "Speed: 11.7ms preprocess, 130.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 130.8ms\n",
            "Speed: 4.6ms preprocess, 130.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 157.8ms\n",
            "Speed: 6.8ms preprocess, 157.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 133.9ms\n",
            "Speed: 4.9ms preprocess, 133.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 130.5ms\n",
            "Speed: 3.9ms preprocess, 130.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 149.8ms\n",
            "Speed: 4.6ms preprocess, 149.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 150.5ms\n",
            "Speed: 4.5ms preprocess, 150.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 240.8ms\n",
            "Speed: 4.7ms preprocess, 240.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 226.3ms\n",
            "Speed: 10.2ms preprocess, 226.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 221.1ms\n",
            "Speed: 7.2ms preprocess, 221.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 327.9ms\n",
            "Speed: 6.0ms preprocess, 327.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 254.1ms\n",
            "Speed: 4.6ms preprocess, 254.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 263.2ms\n",
            "Speed: 4.7ms preprocess, 263.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.4ms\n",
            "Speed: 5.0ms preprocess, 137.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 137.9ms\n",
            "Speed: 3.6ms preprocess, 137.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 154.1ms\n",
            "Speed: 4.0ms preprocess, 154.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 142.1ms\n",
            "Speed: 3.7ms preprocess, 142.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 132.2ms\n",
            "Speed: 3.7ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 132.5ms\n",
            "Speed: 3.9ms preprocess, 132.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 133.0ms\n",
            "Speed: 4.7ms preprocess, 133.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 130.7ms\n",
            "Speed: 3.5ms preprocess, 130.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.6ms\n",
            "Speed: 6.8ms preprocess, 128.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 3 donuts, 128.3ms\n",
            "Speed: 3.9ms preprocess, 128.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 127.0ms\n",
            "Speed: 3.9ms preprocess, 127.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 150.2ms\n",
            "Speed: 4.2ms preprocess, 150.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 138.0ms\n",
            "Speed: 4.4ms preprocess, 138.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 141.5ms\n",
            "Speed: 4.5ms preprocess, 141.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 154.1ms\n",
            "Speed: 11.5ms preprocess, 154.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 143.5ms\n",
            "Speed: 5.4ms preprocess, 143.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 221.5ms\n",
            "Speed: 4.2ms preprocess, 221.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 233.9ms\n",
            "Speed: 4.9ms preprocess, 233.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 223.1ms\n",
            "Speed: 4.3ms preprocess, 223.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 260.3ms\n",
            "Speed: 8.4ms preprocess, 260.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 240.9ms\n",
            "Speed: 4.1ms preprocess, 240.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 144.9ms\n",
            "Speed: 5.3ms preprocess, 144.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 134.6ms\n",
            "Speed: 5.0ms preprocess, 134.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 138.1ms\n",
            "Speed: 4.9ms preprocess, 138.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 131.6ms\n",
            "Speed: 3.7ms preprocess, 131.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 132.2ms\n",
            "Speed: 6.2ms preprocess, 132.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 139.1ms\n",
            "Speed: 10.6ms preprocess, 139.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 148.4ms\n",
            "Speed: 4.3ms preprocess, 148.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 3 donuts, 138.9ms\n",
            "Speed: 4.8ms preprocess, 138.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 handbag, 4 donuts, 145.3ms\n",
            "Speed: 4.4ms preprocess, 145.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 140.2ms\n",
            "Speed: 5.3ms preprocess, 140.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 137.1ms\n",
            "Speed: 4.4ms preprocess, 137.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 129.2ms\n",
            "Speed: 3.7ms preprocess, 129.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 140.5ms\n",
            "Speed: 5.6ms preprocess, 140.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 126.6ms\n",
            "Speed: 10.0ms preprocess, 126.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 4 donuts, 129.4ms\n",
            "Speed: 3.9ms preprocess, 129.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 138.5ms\n",
            "Speed: 4.6ms preprocess, 138.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 230.6ms\n",
            "Speed: 4.3ms preprocess, 230.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 233.4ms\n",
            "Speed: 4.2ms preprocess, 233.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 242.5ms\n",
            "Speed: 7.6ms preprocess, 242.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 256.3ms\n",
            "Speed: 10.3ms preprocess, 256.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 227.8ms\n",
            "Speed: 4.4ms preprocess, 227.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 226.2ms\n",
            "Speed: 8.3ms preprocess, 226.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 143.6ms\n",
            "Speed: 4.4ms preprocess, 143.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 152.4ms\n",
            "Speed: 4.6ms preprocess, 152.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 4 donuts, 141.8ms\n",
            "Speed: 4.2ms preprocess, 141.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 153.1ms\n",
            "Speed: 4.0ms preprocess, 153.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 129.6ms\n",
            "Speed: 4.6ms preprocess, 129.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 4 donuts, 129.1ms\n",
            "Speed: 4.9ms preprocess, 129.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 4 donuts, 124.1ms\n",
            "Speed: 3.9ms preprocess, 124.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 127.7ms\n",
            "Speed: 5.0ms preprocess, 127.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 128.5ms\n",
            "Speed: 3.7ms preprocess, 128.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 143.7ms\n",
            "Speed: 3.7ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 128.1ms\n",
            "Speed: 4.3ms preprocess, 128.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 133.7ms\n",
            "Speed: 3.9ms preprocess, 133.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 153.7ms\n",
            "Speed: 8.0ms preprocess, 153.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 134.9ms\n",
            "Speed: 4.4ms preprocess, 134.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 136.3ms\n",
            "Speed: 4.6ms preprocess, 136.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 139.3ms\n",
            "Speed: 4.3ms preprocess, 139.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 139.4ms\n",
            "Speed: 4.3ms preprocess, 139.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 2 bottles, 4 donuts, 153.9ms\n",
            "Speed: 8.2ms preprocess, 153.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 2 bottles, 4 donuts, 148.1ms\n",
            "Speed: 7.2ms preprocess, 148.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 2 bottles, 4 donuts, 175.0ms\n",
            "Speed: 4.4ms preprocess, 175.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 2 bottles, 4 donuts, 143.2ms\n",
            "Speed: 3.8ms preprocess, 143.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 139.7ms\n",
            "Speed: 4.7ms preprocess, 139.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 191.5ms\n",
            "Speed: 3.9ms preprocess, 191.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 172.1ms\n",
            "Speed: 5.7ms preprocess, 172.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 165.9ms\n",
            "Speed: 5.6ms preprocess, 165.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 264.4ms\n",
            "Speed: 5.3ms preprocess, 264.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 2 bottles, 4 donuts, 257.0ms\n",
            "Speed: 4.7ms preprocess, 257.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 265.2ms\n",
            "Speed: 9.9ms preprocess, 265.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 248.7ms\n",
            "Speed: 5.5ms preprocess, 248.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 303.4ms\n",
            "Speed: 8.6ms preprocess, 303.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 265.1ms\n",
            "Speed: 7.9ms preprocess, 265.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 233.9ms\n",
            "Speed: 14.1ms preprocess, 233.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 161.3ms\n",
            "Speed: 5.8ms preprocess, 161.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 157.2ms\n",
            "Speed: 4.3ms preprocess, 157.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 148.1ms\n",
            "Speed: 6.2ms preprocess, 148.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 138.5ms\n",
            "Speed: 4.5ms preprocess, 138.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 132.4ms\n",
            "Speed: 4.5ms preprocess, 132.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 160.5ms\n",
            "Speed: 5.0ms preprocess, 160.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 164.6ms\n",
            "Speed: 5.6ms preprocess, 164.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 146.5ms\n",
            "Speed: 4.4ms preprocess, 146.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 148.9ms\n",
            "Speed: 5.2ms preprocess, 148.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 136.5ms\n",
            "Speed: 6.4ms preprocess, 136.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 162.2ms\n",
            "Speed: 10.4ms preprocess, 162.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 184.1ms\n",
            "Speed: 4.6ms preprocess, 184.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 169.1ms\n",
            "Speed: 4.6ms preprocess, 169.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 3 donuts, 161.7ms\n",
            "Speed: 5.6ms preprocess, 161.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 bottle, 4 donuts, 156.7ms\n",
            "Speed: 7.3ms preprocess, 156.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 175.2ms\n",
            "Speed: 5.1ms preprocess, 175.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 165.1ms\n",
            "Speed: 4.9ms preprocess, 165.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 183.2ms\n",
            "Speed: 6.0ms preprocess, 183.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 171.0ms\n",
            "Speed: 4.9ms preprocess, 171.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 161.0ms\n",
            "Speed: 7.8ms preprocess, 161.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 168.1ms\n",
            "Speed: 5.9ms preprocess, 168.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 173.8ms\n",
            "Speed: 4.4ms preprocess, 173.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 247.8ms\n",
            "Speed: 9.6ms preprocess, 247.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 241.5ms\n",
            "Speed: 8.6ms preprocess, 241.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 4 donuts, 252.8ms\n",
            "Speed: 7.9ms preprocess, 252.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 252.5ms\n",
            "Speed: 5.4ms preprocess, 252.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 253.4ms\n",
            "Speed: 10.4ms preprocess, 253.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 262.9ms\n",
            "Speed: 5.2ms preprocess, 262.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 441.0ms\n",
            "Speed: 5.0ms preprocess, 441.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 288.3ms\n",
            "Speed: 7.6ms preprocess, 288.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 153.7ms\n",
            "Speed: 14.3ms preprocess, 153.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 158.9ms\n",
            "Speed: 5.0ms preprocess, 158.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 155.0ms\n",
            "Speed: 4.7ms preprocess, 155.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 157.5ms\n",
            "Speed: 4.3ms preprocess, 157.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 backpack, 1 donut, 153.2ms\n",
            "Speed: 4.3ms preprocess, 153.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 149.4ms\n",
            "Speed: 4.1ms preprocess, 149.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 170.1ms\n",
            "Speed: 4.2ms preprocess, 170.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 148.3ms\n",
            "Speed: 4.3ms preprocess, 148.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 150.4ms\n",
            "Speed: 4.2ms preprocess, 150.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 162.1ms\n",
            "Speed: 5.6ms preprocess, 162.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 144.2ms\n",
            "Speed: 4.6ms preprocess, 144.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 150.3ms\n",
            "Speed: 5.5ms preprocess, 150.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 donut, 146.3ms\n",
            "Speed: 4.1ms preprocess, 146.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 donut, 146.6ms\n",
            "Speed: 15.7ms preprocess, 146.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 1 person, 1 bottle, 1 donut, 140.6ms\n",
            "Speed: 5.2ms preprocess, 140.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 134.7ms\n",
            "Speed: 4.1ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 129.3ms\n",
            "Speed: 10.5ms preprocess, 129.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 130.2ms\n",
            "Speed: 4.6ms preprocess, 130.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 133.8ms\n",
            "Speed: 3.8ms preprocess, 133.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 131.7ms\n",
            "Speed: 4.2ms preprocess, 131.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 136.6ms\n",
            "Speed: 4.3ms preprocess, 136.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 187.5ms\n",
            "Speed: 3.8ms preprocess, 187.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 273.4ms\n",
            "Speed: 4.9ms preprocess, 273.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 233.9ms\n",
            "Speed: 5.2ms preprocess, 233.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 donuts, 244.2ms\n",
            "Speed: 10.1ms preprocess, 244.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 264.7ms\n",
            "Speed: 4.4ms preprocess, 264.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 249.7ms\n",
            "Speed: 6.1ms preprocess, 249.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 138.2ms\n",
            "Speed: 4.1ms preprocess, 138.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 161.6ms\n",
            "Speed: 3.8ms preprocess, 161.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 170.4ms\n",
            "Speed: 5.5ms preprocess, 170.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 194.6ms\n",
            "Speed: 6.8ms preprocess, 194.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 182.1ms\n",
            "Speed: 4.9ms preprocess, 182.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 154.1ms\n",
            "Speed: 4.8ms preprocess, 154.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 141.0ms\n",
            "Speed: 5.2ms preprocess, 141.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 3 donuts, 208.4ms\n",
            "Speed: 7.9ms preprocess, 208.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 174.9ms\n",
            "Speed: 5.5ms preprocess, 174.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 140.1ms\n",
            "Speed: 8.1ms preprocess, 140.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 145.6ms\n",
            "Speed: 6.5ms preprocess, 145.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 137.9ms\n",
            "Speed: 7.2ms preprocess, 137.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 137.5ms\n",
            "Speed: 3.9ms preprocess, 137.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 140.1ms\n",
            "Speed: 4.1ms preprocess, 140.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 130.9ms\n",
            "Speed: 6.7ms preprocess, 130.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 236.9ms\n",
            "Speed: 4.5ms preprocess, 236.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 228.6ms\n",
            "Speed: 8.1ms preprocess, 228.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 2 backpacks, 3 donuts, 221.9ms\n",
            "Speed: 5.6ms preprocess, 221.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 231.2ms\n",
            "Speed: 8.6ms preprocess, 231.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 231.3ms\n",
            "Speed: 4.2ms preprocess, 231.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 153.4ms\n",
            "Speed: 4.1ms preprocess, 153.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 158.5ms\n",
            "Speed: 4.5ms preprocess, 158.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 133.8ms\n",
            "Speed: 4.6ms preprocess, 133.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 130.8ms\n",
            "Speed: 4.5ms preprocess, 130.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 157.7ms\n",
            "Speed: 8.2ms preprocess, 157.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 157.7ms\n",
            "Speed: 4.1ms preprocess, 157.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 150.4ms\n",
            "Speed: 6.2ms preprocess, 150.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 donut, 149.1ms\n",
            "Speed: 4.2ms preprocess, 149.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 143.5ms\n",
            "Speed: 5.3ms preprocess, 143.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 151.5ms\n",
            "Speed: 4.3ms preprocess, 151.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 129.5ms\n",
            "Speed: 4.1ms preprocess, 129.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 128.3ms\n",
            "Speed: 3.9ms preprocess, 128.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 135.1ms\n",
            "Speed: 3.8ms preprocess, 135.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 132.1ms\n",
            "Speed: 4.7ms preprocess, 132.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 161.8ms\n",
            "Speed: 4.6ms preprocess, 161.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 230.1ms\n",
            "Speed: 9.7ms preprocess, 230.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 234.5ms\n",
            "Speed: 4.2ms preprocess, 234.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "\n",
            "0: 384x640 2 persons, 1 backpack, 251.1ms\n",
            "Speed: 4.9ms preprocess, 251.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Extracted abnormal landmarks: 25005\n",
            "Extracted normal landmarks: 21961\n"
          ]
        }
      ],
      "source": [
        "abnormal_clip_dir = '/content/drive/MyDrive/capstone_data/data/Training/clipped_videos/abnormal'\n",
        "normal_clip_dir = '/content/drive/MyDrive/capstone_data/data/Training/clipped_videos/normal'\n",
        "\n",
        "abnormal_landmarks = process_clips(abnormal_clip_dir)\n",
        "normal_landmarks = process_clips(normal_clip_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZL3jFvkvspg9",
        "outputId": "25cb9961-e90d-4cc7-c00b-d1f195086851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracted abnormal landmarks: 25005\n",
            "Extracted normal landmarks: 21961\n"
          ]
        }
      ],
      "source": [
        "print(f\"Extracted abnormal landmarks: {len(abnormal_landmarks)}\")\n",
        "print(f\"Extracted normal landmarks: {len(normal_landmarks)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em-HzlBKk_9g"
      },
      "source": [
        "#3. 데이터 패딩 및 준비"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m_iM_OCdklQw",
        "outputId": "5eb19345-ebfc-43b7-d21b-7a33566211c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding abnormal landmarks...\n",
            "Padded landmarks count: 25005\n",
            "Padding normal landmarks...\n",
            "Padded landmarks count: 21961\n",
            "Valid abnormal landmarks after padding: 25005\n",
            "Valid normal landmarks after padding: 21961\n",
            "Total valid landmarks: 46966\n",
            "Training samples: 37572, Validation samples: 9394\n",
            "Train DataLoader created with 37572 samples.\n",
            "Validation DataLoader created with 9394 samples.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split  # train_test_split 임포트 추가\n",
        "def pad_landmarks(landmarks, target_length):\n",
        "    padded_landmarks = []\n",
        "    for i, lm in enumerate(landmarks):\n",
        "        if lm is None or len(lm) == 0:\n",
        "            print(f\"Invalid landmark found at index {i}\")\n",
        "            continue\n",
        "        if len(lm) > target_length:\n",
        "            lm = lm[:target_length]\n",
        "        elif len(lm) < target_length:\n",
        "            lm += [[0, 0]] * (target_length - len(lm))\n",
        "        if len(lm) == target_length:\n",
        "            padded_landmarks.append(lm)\n",
        "        else:\n",
        "            print(f\"Landmark at index {i} has incorrect length after processing: {len(lm)}\")\n",
        "    print(f\"Padded landmarks count: {len(padded_landmarks)}\")\n",
        "    return padded_landmarks\n",
        "\n",
        "def prepare_data(abnormal_landmarks, normal_landmarks, sequence_length=10, test_size=0.2):\n",
        "    print(\"Padding abnormal landmarks...\")\n",
        "    abnormal_landmarks = pad_landmarks(abnormal_landmarks, sequence_length)\n",
        "    print(\"Padding normal landmarks...\")\n",
        "    normal_landmarks = pad_landmarks(normal_landmarks, sequence_length)\n",
        "\n",
        "    abnormal_landmarks = [lm for lm in abnormal_landmarks if lm is not None and len(lm) == sequence_length]\n",
        "    normal_landmarks = [lm for lm in normal_landmarks if lm is not None and len(lm) == sequence_length]\n",
        "\n",
        "    X = abnormal_landmarks + normal_landmarks\n",
        "    y = [1] * len(abnormal_landmarks) + [0] * len(normal_landmarks)\n",
        "\n",
        "    print(f\"Valid abnormal landmarks after padding: {len(abnormal_landmarks)}\")\n",
        "    print(f\"Valid normal landmarks after padding: {len(normal_landmarks)}\")\n",
        "    print(f\"Total valid landmarks: {len(X)}\")\n",
        "\n",
        "    if len(X) == 0 or len(y) == 0:\n",
        "        raise ValueError(\"No valid data found after filtering None and invalid sequences.\")\n",
        "\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
        "\n",
        "    print(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n",
        "\n",
        "    train_dataset = LandmarkDataset(X_train, y_train)\n",
        "    val_dataset = LandmarkDataset(X_val, y_val)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "class LandmarkDataset(Dataset):\n",
        "    def __init__(self, landmarks, labels):\n",
        "        self.landmarks = landmarks\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.landmarks)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.landmarks[idx], dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.float32)\n",
        "\n",
        "sequence_length = 10\n",
        "try:\n",
        "    train_loader, val_loader = prepare_data(abnormal_landmarks, normal_landmarks, sequence_length)\n",
        "    print(f\"Train DataLoader created with {len(train_loader.dataset)} samples.\")\n",
        "    print(f\"Validation DataLoader created with {len(val_loader.dataset)} samples.\")\n",
        "except ValueError as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5hKLu7KnCJ-"
      },
      "source": [
        "#LSTM 모델 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3CLKPDS3nFwr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    preds = torch.sigmoid(outputs) > 0.5\n",
        "    correct = (preds == labels).float()\n",
        "    accuracy = correct.sum() / len(correct)\n",
        "    return accuracy\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers=2, dropout=0.5):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(2, x.size(0), self.hidden_size).to(x.device)\n",
        "        c0 = torch.zeros(2, x.size(0), self.hidden_size).to(x.device)\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "def train_model(num_epochs, train_loader, val_loader, criterion, learning_rate=0.0005):\n",
        "    model = LSTMModel(input_size, hidden_size, output_size, num_layers, dropout)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_train_loss = 0.0\n",
        "        running_train_accuracy = 0.0\n",
        "        for i, (landmarks, labels) in enumerate(train_loader):\n",
        "            landmarks, labels = landmarks.to(torch.float32), labels.to(torch.float32)\n",
        "\n",
        "            outputs = model(landmarks).squeeze()\n",
        "            labels = labels.squeeze()\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_train_loss += loss.item()\n",
        "            running_train_accuracy += calculate_accuracy(outputs, labels).item()\n",
        "\n",
        "        model.eval()\n",
        "        running_val_loss = 0.0\n",
        "        running_val_accuracy = 0.0\n",
        "        with torch.no_grad():\n",
        "            for i, (landmarks, labels) in enumerate(val_loader):\n",
        "                landmarks, labels = landmarks.to(torch.float32), labels.to(torch.float32)\n",
        "\n",
        "                outputs = model(landmarks).squeeze()\n",
        "                labels = labels.squeeze()\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                running_val_loss += loss.item()\n",
        "                running_val_accuracy += calculate_accuracy(outputs, labels).item()\n",
        "\n",
        "        train_loss = running_train_loss / len(train_loader)\n",
        "        val_loss = running_val_loss / len(val_loader)\n",
        "        train_accuracy = running_train_accuracy / len(train_loader)\n",
        "        val_accuracy = running_val_accuracy / len(val_loader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, \"\n",
        "              f\"Train Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    return model, train_losses, val_losses, train_accuracies, val_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiabYrE5nJYt"
      },
      "source": [
        "## LSTM 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kzcbvqDInIF9",
        "outputId": "9fe3af0f-e472-4085-b714-0bb882988932"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Loss: 0.6914, Validation Loss: 0.6909, Train Accuracy: 0.5310, Validation Accuracy: 0.5325\n",
            "Epoch [2/50], Loss: 0.6908, Validation Loss: 0.6918, Train Accuracy: 0.5326, Validation Accuracy: 0.5406\n",
            "Epoch [3/50], Loss: 0.6909, Validation Loss: 0.6906, Train Accuracy: 0.5337, Validation Accuracy: 0.5356\n",
            "Epoch [4/50], Loss: 0.6905, Validation Loss: 0.6899, Train Accuracy: 0.5355, Validation Accuracy: 0.5360\n",
            "Epoch [5/50], Loss: 0.6872, Validation Loss: 0.6811, Train Accuracy: 0.5444, Validation Accuracy: 0.5516\n",
            "Epoch [6/50], Loss: 0.6794, Validation Loss: 0.6778, Train Accuracy: 0.5645, Validation Accuracy: 0.5661\n",
            "Epoch [7/50], Loss: 0.6743, Validation Loss: 0.6686, Train Accuracy: 0.5768, Validation Accuracy: 0.5863\n",
            "Epoch [8/50], Loss: 0.6699, Validation Loss: 0.6659, Train Accuracy: 0.5809, Validation Accuracy: 0.5763\n",
            "Epoch [9/50], Loss: 0.6685, Validation Loss: 0.6639, Train Accuracy: 0.5848, Validation Accuracy: 0.5888\n",
            "Epoch [10/50], Loss: 0.6667, Validation Loss: 0.6623, Train Accuracy: 0.5861, Validation Accuracy: 0.5923\n",
            "Epoch [11/50], Loss: 0.6669, Validation Loss: 0.6609, Train Accuracy: 0.5877, Validation Accuracy: 0.5905\n",
            "Epoch [12/50], Loss: 0.6653, Validation Loss: 0.6578, Train Accuracy: 0.5869, Validation Accuracy: 0.5948\n",
            "Epoch [13/50], Loss: 0.6637, Validation Loss: 0.6623, Train Accuracy: 0.5893, Validation Accuracy: 0.5912\n",
            "Epoch [14/50], Loss: 0.6637, Validation Loss: 0.6594, Train Accuracy: 0.5944, Validation Accuracy: 0.6046\n",
            "Epoch [15/50], Loss: 0.6620, Validation Loss: 0.6540, Train Accuracy: 0.5969, Validation Accuracy: 0.6111\n",
            "Epoch [16/50], Loss: 0.6605, Validation Loss: 0.6608, Train Accuracy: 0.5969, Validation Accuracy: 0.5935\n",
            "Epoch [17/50], Loss: 0.6613, Validation Loss: 0.6563, Train Accuracy: 0.5952, Validation Accuracy: 0.6066\n",
            "Epoch [18/50], Loss: 0.6598, Validation Loss: 0.6562, Train Accuracy: 0.5995, Validation Accuracy: 0.6078\n",
            "Epoch [19/50], Loss: 0.6597, Validation Loss: 0.6532, Train Accuracy: 0.5995, Validation Accuracy: 0.6102\n",
            "Epoch [20/50], Loss: 0.6588, Validation Loss: 0.6618, Train Accuracy: 0.6001, Validation Accuracy: 0.6075\n",
            "Epoch [21/50], Loss: 0.6585, Validation Loss: 0.6570, Train Accuracy: 0.6018, Validation Accuracy: 0.6065\n",
            "Epoch [22/50], Loss: 0.6585, Validation Loss: 0.6613, Train Accuracy: 0.6013, Validation Accuracy: 0.5969\n",
            "Epoch [23/50], Loss: 0.6577, Validation Loss: 0.6515, Train Accuracy: 0.6035, Validation Accuracy: 0.6057\n",
            "Epoch [24/50], Loss: 0.6575, Validation Loss: 0.6525, Train Accuracy: 0.6027, Validation Accuracy: 0.6056\n",
            "Epoch [25/50], Loss: 0.6567, Validation Loss: 0.6619, Train Accuracy: 0.6020, Validation Accuracy: 0.6036\n",
            "Epoch [26/50], Loss: 0.6562, Validation Loss: 0.6529, Train Accuracy: 0.6030, Validation Accuracy: 0.6089\n",
            "Epoch [27/50], Loss: 0.6554, Validation Loss: 0.6549, Train Accuracy: 0.6039, Validation Accuracy: 0.6146\n",
            "Epoch [28/50], Loss: 0.6556, Validation Loss: 0.6556, Train Accuracy: 0.6056, Validation Accuracy: 0.6014\n",
            "Epoch [29/50], Loss: 0.6545, Validation Loss: 0.6497, Train Accuracy: 0.6047, Validation Accuracy: 0.6164\n",
            "Epoch [30/50], Loss: 0.6543, Validation Loss: 0.6514, Train Accuracy: 0.6094, Validation Accuracy: 0.6124\n",
            "Epoch [31/50], Loss: 0.6539, Validation Loss: 0.6526, Train Accuracy: 0.6072, Validation Accuracy: 0.6097\n",
            "Epoch [32/50], Loss: 0.6542, Validation Loss: 0.6494, Train Accuracy: 0.6068, Validation Accuracy: 0.6208\n",
            "Epoch [33/50], Loss: 0.6537, Validation Loss: 0.6486, Train Accuracy: 0.6094, Validation Accuracy: 0.6186\n",
            "Epoch [34/50], Loss: 0.6521, Validation Loss: 0.6533, Train Accuracy: 0.6107, Validation Accuracy: 0.6094\n",
            "Epoch [35/50], Loss: 0.6526, Validation Loss: 0.6534, Train Accuracy: 0.6090, Validation Accuracy: 0.6176\n",
            "Epoch [36/50], Loss: 0.6518, Validation Loss: 0.6494, Train Accuracy: 0.6100, Validation Accuracy: 0.6149\n",
            "Epoch [37/50], Loss: 0.6528, Validation Loss: 0.6486, Train Accuracy: 0.6101, Validation Accuracy: 0.6192\n",
            "Epoch [38/50], Loss: 0.6515, Validation Loss: 0.6516, Train Accuracy: 0.6107, Validation Accuracy: 0.6170\n",
            "Epoch [39/50], Loss: 0.6518, Validation Loss: 0.6548, Train Accuracy: 0.6100, Validation Accuracy: 0.6096\n",
            "Epoch [40/50], Loss: 0.6498, Validation Loss: 0.6517, Train Accuracy: 0.6143, Validation Accuracy: 0.6120\n",
            "Epoch [41/50], Loss: 0.6503, Validation Loss: 0.6436, Train Accuracy: 0.6111, Validation Accuracy: 0.6234\n",
            "Epoch [42/50], Loss: 0.6478, Validation Loss: 0.6437, Train Accuracy: 0.6143, Validation Accuracy: 0.6196\n",
            "Epoch [43/50], Loss: 0.6493, Validation Loss: 0.6433, Train Accuracy: 0.6140, Validation Accuracy: 0.6216\n",
            "Epoch [44/50], Loss: 0.6468, Validation Loss: 0.6437, Train Accuracy: 0.6160, Validation Accuracy: 0.6219\n",
            "Epoch [45/50], Loss: 0.6459, Validation Loss: 0.6461, Train Accuracy: 0.6176, Validation Accuracy: 0.6203\n",
            "Epoch [46/50], Loss: 0.6455, Validation Loss: 0.6430, Train Accuracy: 0.6177, Validation Accuracy: 0.6201\n",
            "Epoch [47/50], Loss: 0.6445, Validation Loss: 0.6518, Train Accuracy: 0.6193, Validation Accuracy: 0.6033\n",
            "Epoch [48/50], Loss: 0.6410, Validation Loss: 0.6633, Train Accuracy: 0.6215, Validation Accuracy: 0.6037\n",
            "Epoch [49/50], Loss: 0.6414, Validation Loss: 0.6451, Train Accuracy: 0.6225, Validation Accuracy: 0.6183\n",
            "Epoch [50/50], Loss: 0.6401, Validation Loss: 0.6530, Train Accuracy: 0.6224, Validation Accuracy: 0.6109\n"
          ]
        }
      ],
      "source": [
        "input_size = 2\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "\n",
        "num_epochs = 50\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "learning_rate = 0.0005\n",
        "\n",
        "model, train_losses, val_losses, train_accuracies, val_accuracies = train_model(num_epochs, train_loader, val_loader, criterion, learning_rate)\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/capstone_data/data/models/이상감지_모델_절도_20.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl0eyiOCosva"
      },
      "source": [
        "# 손실 및 정확도 그래프 그리기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g77ZIyLvot9M",
        "outputId": "1803a951-8c02-4978-95d6-09a48b64f67e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 손실 그래프 그리기\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
        "plt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Validation Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# 정확도 그래프 그리기\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), train_accuracies, label='Train Accuracy')\n",
        "plt.plot(range(1, num_epochs + 1), val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Validation Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4A6BRLMOBhLG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}